{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"Bespokefit_smee <p>Generate a Bespoke Force-Field Parametrization Quickly and Reliably. Developed in the Cole Group at Newcastle University. Please see the documentation.</p> <p>Warning: This code is experimental and under active development. It is not guaranteed to provide correct results, the documentation and testing is incomplete, and the API may change without notice.</p> <p>Please note that the MACE models currently used are released under the Academic Software License which does not permit commercial use. We will incorporate MIT-licensed models soon.</p>"},{"location":"#what-is-bespokefit_smee","title":"What is Bespokefit_smee?","text":"<p>Bespokefit_smee is a Force-Field parametrization tool. For a given molecule, it will generate a data set of conformers using machine learning models in OpenMM-ML simulations. This dataset is used to optimise the force field parameters.</p>"},{"location":"#installation","title":"Installation","text":"<p>Ensuring that you have pixi installed, run: <pre><code>git clone https://github.com/fjclark/bespokefit_smee.git\ncd bespokefit_smee\npixi install\n</code></pre></p>"},{"location":"#usage","title":"Usage","text":"<p>First, start a shell in the current environment (this must be run from the <code>bespokefit_smee</code> base directory) <pre><code>pixi shell\n</code></pre> For more information on activating pixi environments, see the documentation.</p> <p>Run with command line arguments: <pre><code>bespokefit_smee train --parameterisation-settings.smiles \"CCC(CC)C(=O)Nc2cc(NC(=O)c1c(Cl)cccc1Cl)ccn2\"\n</code></pre></p> <p>Sensible defaults have been set, but all available options can be viewed with: <pre><code>bespokefit_smee train --help\n</code></pre></p> <p>Run from a yaml file: <pre><code>bespokefit_smee write-default-yaml default.yaml\n# Modify the yaml to set the desired smiles\nbespokefit_smee train-from-yaml default.yaml\n</code></pre></p> <p>For more details on the theory and implementation, please see the documentation.</p>"},{"location":"#copyright","title":"Copyright","text":"<p>Copyright (c) 2025, Thomas James Pope, Newcastle University, UK</p> <p>Copyright (c) 2025, Finlay Clark, Newcastle University, UK</p> <p>This package includes models from other projects under the MIT license. See <code>bespokefit_smee/models/LICENSES.md</code> for details.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>All early development was completed by Thomas James Pope. Many ideas taken from Simon Boothroyd's super helpful python-template.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"development/","title":"Development","text":""},{"location":"development/#writing-code","title":"Writing Code","text":"<p>To create a development environment, you must have <code>mamba</code> installed.</p> <p>A development conda environment can be created and activated with:</p> <pre><code>make env\nmamba activate red\n</code></pre> <p>Some handy <code>make</code> commands are available: <pre><code>make lint # Lint the codebase with Ruff\nmake format # Format the codebase with Ruff\nmake type-check # Type-check the codebase with Mypy\nmake test # Run the unit tests with Pytest\n</code></pre></p> <p>To serve the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"development/#publishing","title":"Publishing","text":""},{"location":"development/#pypi","title":"PyPI","text":"<p>There is a GitHub Actions workflow that will automatically publish to PyPI when a new tag is pushed: <pre><code>git tag &lt;new version&gt;\ngit push origin &lt;new version&gt;\n</code></pre></p>"},{"location":"theory/","title":"Theory","text":"<p>From a SMILES string, we generate a initial parametrization using a default open-ff force field - and optionally, adding in modified-Seminario derived bond and angle force constants. This is used to generate a dataset of conformers by running either ML-Potential MD of Force-Field MD and grabbing a number of snapshots. For every snapshot, the energies and forces are taken using the ML-Potental.</p> <p>This dataset is used to minimize the given force field parameters using the ADAM stochastic optimization method, where the loss function is the squared difference between energies and forces for the conformer dataset predicted by the force-field parametrization and the stored values calculated with the ML-potential.</p> <p>After a given number of epochs, the new parametrization is stored. The new force-field is used to generate another set of MD snapshots, which are used in the same way to further optimize the force field. This continues for a given number of iterations, where the relative reduction is error is tracked. The number of iterations should be increased up to convergence.</p> <p>Four methods for generating the initial dataset are implemented:</p> <p>1 - \"DATA\" : Read the dataset from a file</p> <p>2 - \"MLMD\" : Run the ML-Potential MD to get the snapshots. This is the most expensive option.</p> <p>3 - \"MMMD\" : Run Force-Field MD using the initial guess to generate the snapshots. Then use the ML-Potential to generate energies and forces</p> <p>4 - \"cMMMD\" : Run Force-Field MD using the initial guess to generate the snapshots. Cluster the snapshots with respect to their pairwise RMSD and then use the ML-Potential to generate energies and forces</p> <p>The functional form of the force-field is as follows:</p> <ul> <li>Bonds and angles are defined by a harmonic function, \\(u(x;k,x_0)=\\frac{k}{2}\\left(x-x_0\\right)^2\\), where the position of the minimum, \\(x_0\\), and the magnitude, \\(k\\), are the fitting parameters.</li> <li>Proper and improper torsions are defined by a set of cosine functions, \\(u_p(\\phi;k,\\phi_0)=k\\left(1+\\cos{\\left(p\\phi-\\phi_0\\right)}\\right)\\), where the phase, \\(\\phi_0\\), and the magnitude, \\(k\\), are the fitted parameters. Here, proper torsions are expanded to include four periodicities, whereas improper torsions include only one. It is also noted that for symmetry, the phase \\(\\phi_0\\) is expected to be either 0 or \\(\\pi\\)</li> </ul> <p>To stabilize and speed up convergence of the parameter fitting, these potentials are linearized.</p> <p>The linearization of the harmonic terms followed the approach by espaloma, where the minimum is assumed to be within a window given by \\(x_1\\) and \\(x_2\\), such that the fitting parameters may by remapped onto linear terms,</p> \\[k_1=k\\frac{x_2-x_0}{x_2-x_1} \\quad\\text{and}\\quad k_2=k\\frac{x_0-x_1}{x_2-x_1}\\] <p>These terms give the original parameters via,</p> \\[k=k_1+k_2 \\quad\\text{and}\\quad x_0=\\frac{k_1x_1+k_2x_2}{k_1+k_2}\\] <p>Crucially, the gradient along \\(k_1\\) and \\(k_2\\) behaves more reliably and so the parameters minimize faster.</p> <p>In a similar way, the cosine functions are linearized by defining a phase window of 0 to \\(\\pi\\), such that the parameters may be mapped onto,</p> \\[k_0=\\frac{k}{2}\\left(1+\\cos{\\phi_0}\\right) \\quad\\text{and}\\quad k_{\\pi}=\\frac{k}{2}\\left(1-\\cos{\\phi_0}\\right)\\] <p>which yield the original parameters via,</p> \\[k=k_0+k_{\\pi} \\quad\\text{and}\\quad \\cos{\\phi_0}=\\frac{k_0-k_{\\pi}}{k_0+k_{\\pi}}\\] <p>Again, the gradient along \\(k_0\\) and \\(k_{\\pi}\\) is more reliable and the parametrization proceed faster.</p>"},{"location":"reference/","title":"Index","text":""},{"location":"reference/#bespokefit_smee","title":"bespokefit_smee","text":"<p>Fast parameterisation of MM force fields using MLPs.</p> <p>Modules:</p> <ul> <li> <code>analyse</code>           \u2013            <p>Functionality for analysing the results of a BespokeFitSMEE run.</p> </li> <li> <code>find_torsions</code>           \u2013            <p>Functionality for finding and sampling torsions in a molecule.</p> </li> <li> <code>loss_functions</code>           \u2013            <p>Loss functions for tuning the forcefield</p> </li> <li> <code>metadynamics</code>           \u2013            <p>The code below is slightly modified from the original in OpenMM</p> </li> <li> <code>mlp</code>           \u2013            <p>Functionality for creating Open</p> </li> <li> <code>models</code>           \u2013            <p>Compiled models</p> </li> <li> <code>msm</code>           \u2013            <p>Functionality for applying the modified Seminario method.</p> </li> <li> <code>outputs</code>           \u2013            <p>Functionality for handling the outputs of a workflow.</p> </li> <li> <code>parameterise</code>           \u2013            <p>Functionality for generating the initial parameterisation.</p> </li> <li> <code>sample</code>           \u2013            <p>Functionality to obtain samples to fit the force field to.</p> </li> <li> <code>settings</code>           \u2013            <p>Pydantic models which control/validate the settings.</p> </li> <li> <code>tests</code>           \u2013            <p>Unit and integration tests for bespokefit_smee</p> </li> <li> <code>train</code>           \u2013            <p>Apply OpenFF parameters to molecule, cluster conformers by RMSD and train</p> </li> <li> <code>utils</code>           \u2013            <p>Utilities for the bespokefit_smee package.</p> </li> <li> <code>workflow</code>           \u2013            <p>Implements the overall workflow for fitting a bespoke force field.</p> </li> <li> <code>writers</code>           \u2013            <p>WRITERS:</p> </li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>bespokefit_smee<ul> <li>analyse</li> <li>find_torsions</li> <li>loss_functions</li> <li>metadynamics</li> <li>mlp</li> <li>models<ul> <li>compile_aimnet2_ens_models</li> </ul> </li> <li>msm</li> <li>outputs</li> <li>parameterise</li> <li>sample</li> <li>settings</li> <li>train</li> <li>utils<ul> <li>aimnet2</li> <li>rdkit_bespoke_wrapper</li> <li>register</li> <li>typing</li> </ul> </li> <li>workflow</li> <li>writers</li> </ul> </li> </ul>"},{"location":"reference/analyse/","title":"analyse","text":""},{"location":"reference/analyse/#bespokefit_smee.analyse","title":"analyse","text":"<p>Functionality for analysing the results of a BespokeFitSMEE run.</p> <p>Functions:</p> <ul> <li> <code>read_errors</code>             \u2013              <p>Read all energy and force data from the HDF5 files.</p> </li> <li> <code>load_force_fields</code>             \u2013              <p>Load the .offxml files from the given paths.</p> </li> <li> <code>plot_energy_correlation</code>             \u2013              <p>Plot the correlation between reference and predicted values. For</p> </li> <li> <code>get_mol_image_with_atom_idxs</code>             \u2013              <p>Generate a PIL Image of the molecule with atom indices labeled.</p> </li> <li> <code>plot_force_error_by_atom_idx</code>             \u2013              <p>Plot a seaborn swarmplot of the force errors by atom index.</p> </li> <li> <code>plot_error_statistics</code>             \u2013              <p>Plot the error statistics for the energy and force errors.</p> </li> <li> <code>analyse_workflow</code>             \u2013              <p>Analyse the results of a BespokeFitSMEE workflow.</p> </li> </ul>"},{"location":"reference/analyse/#bespokefit_smee.analyse.read_errors","title":"read_errors","text":"<pre><code>read_errors(\n    paths_by_iter: dict[int, Path],\n) -&gt; dict[str, dict[int, NDArray[float64]]]\n</code></pre> <p>Read all energy and force data from the HDF5 files.</p> <p>Returns:     Dictionary with keys: 'energy_reference', 'energy_predicted', 'energy_differences',     'forces_reference', 'forces_predicted', 'forces_differences'.     Each value is a dict mapping iteration number to numpy array.</p> Source code in <code>bespokefit_smee/analyse.py</code> <pre><code>def read_errors(\n    paths_by_iter: dict[int, Path],\n) -&gt; dict[str, dict[int, npt.NDArray[np.float64]]]:\n    \"\"\"Read all energy and force data from the HDF5 files.\n\n    Returns:\n        Dictionary with keys: 'energy_reference', 'energy_predicted', 'energy_differences',\n        'forces_reference', 'forces_predicted', 'forces_differences'.\n        Each value is a dict mapping iteration number to numpy array.\n    \"\"\"\n\n    results: dict[str, dict[int, npt.NDArray[np.float64]]] = {\n        \"energy_reference\": {},\n        \"energy_predicted\": {},\n        \"energy_differences\": {},\n        \"forces_reference\": {},\n        \"forces_predicted\": {},\n        \"forces_differences\": {},\n    }\n\n    for i, filepath in paths_by_iter.items():\n        with h5py.File(filepath, \"r\") as f:\n            results[\"energy_reference\"][i] = f[\"energy_reference\"][:]\n            results[\"energy_predicted\"][i] = f[\"energy_predicted\"][:]\n            results[\"energy_differences\"][i] = f[\"energy_differences\"][:]\n            results[\"forces_reference\"][i] = f[\"forces_reference\"][:]\n            results[\"forces_predicted\"][i] = f[\"forces_predicted\"][:]\n            results[\"forces_differences\"][i] = f[\"forces_differences\"][:]\n            results[\"n_atoms\"] = f.attrs[\"n_atoms\"]\n            results[\"n_conformers\"] = f.attrs[\"n_conformers\"]\n\n    return results\n</code></pre>"},{"location":"reference/analyse/#bespokefit_smee.analyse.load_force_fields","title":"load_force_fields","text":"<pre><code>load_force_fields(\n    paths_by_iter: dict[int, Path],\n) -&gt; dict[int, str]\n</code></pre> <p>Load the .offxml files from the given paths.</p> Source code in <code>bespokefit_smee/analyse.py</code> <pre><code>def load_force_fields(paths_by_iter: dict[int, Path]) -&gt; dict[int, str]:\n    \"\"\"Load the .offxml files from the given paths.\"\"\"\n    return {i: ForceField(p) for i, p in paths_by_iter.items()}\n</code></pre>"},{"location":"reference/analyse/#bespokefit_smee.analyse.plot_energy_correlation","title":"plot_energy_correlation","text":"<pre><code>plot_energy_correlation(\n    fig: Figure,\n    ax: Axes,\n    reference: dict[int, NDArray[float64]],\n    predicted: dict[int, NDArray[float64]],\n) -&gt; None\n</code></pre> <p>Plot the correlation between reference and predicted values. For forces, convert to the magnitude of the forces.</p> Source code in <code>bespokefit_smee/analyse.py</code> <pre><code>def plot_energy_correlation(\n    fig: Figure,\n    ax: Axes,\n    reference: dict[int, npt.NDArray[np.float64]],\n    predicted: dict[int, npt.NDArray[np.float64]],\n) -&gt; None:\n    \"\"\"Plot the correlation between reference and predicted values. For\n    forces, convert to the magnitude of the forces.\"\"\"\n\n    for i in reference.keys():\n        ax.scatter(reference[i], predicted[i], alpha=0.5, label=f\"Iteration {i}\")\n    all_values = np.concatenate(list(reference.values()) + list(predicted.values()))\n    min_val = all_values.min()\n    max_val = all_values.max()\n    ax.plot([min_val, max_val], [min_val, max_val], color=\"red\", linestyle=\"--\")\n    ax.set_xlabel(\"Reference Energy / kcal mol$^{-1}$\")\n    ax.set_ylabel(\"Predicted Energy / kcal mol$^{-1}$\")\n    ax.set_title(\"Energy Correlation Plot\")\n    ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n</code></pre>"},{"location":"reference/analyse/#bespokefit_smee.analyse.get_mol_image_with_atom_idxs","title":"get_mol_image_with_atom_idxs","text":"<pre><code>get_mol_image_with_atom_idxs(\n    molecule: Molecule, width: int = 300, height: int = 300\n) -&gt; Image\n</code></pre> <p>Generate a PIL Image of the molecule with atom indices labeled.</p> Source code in <code>bespokefit_smee/analyse.py</code> <pre><code>def get_mol_image_with_atom_idxs(\n    molecule: Molecule, width: int = 300, height: int = 300\n) -&gt; Image.Image:\n    \"\"\"Generate a PIL Image of the molecule with atom indices labeled.\"\"\"\n    molecule_copy = Molecule(molecule)\n    molecule_copy._conformers = None\n\n    rdmol = molecule_copy.to_rdkit()\n\n    # Build labels like \"C:0\", \"C:1\", \"C:2\", ...\n    atom_labels = {\n        atom.GetIdx(): f\"{atom.GetSymbol()}:{atom.GetIdx()}\"\n        for atom in rdmol.GetAtoms()\n    }\n\n    drawer = Draw.MolDraw2DCairo(width, height)\n    opts = drawer.drawOptions()\n    for idx, label in atom_labels.items():\n        opts.atomLabels[idx] = label\n\n    Draw.rdMolDraw2D.PrepareAndDrawMolecule(drawer, rdmol)\n    drawer.FinishDrawing()\n\n    # Convert PNG bytes to PIL Image\n    png_data = drawer.GetDrawingText()\n    img = Image.open(io.BytesIO(png_data))\n\n    return img\n</code></pre>"},{"location":"reference/analyse/#bespokefit_smee.analyse.plot_force_error_by_atom_idx","title":"plot_force_error_by_atom_idx","text":"<pre><code>plot_force_error_by_atom_idx(\n    fig: Figure,\n    ax: Axes,\n    errors: dict[int, NDArray[float64]],\n    mol: Molecule,\n) -&gt; None\n</code></pre> <p>Plot a seaborn swarmplot of the force errors by atom index.</p> Source code in <code>bespokefit_smee/analyse.py</code> <pre><code>def plot_force_error_by_atom_idx(\n    fig: Figure,\n    ax: Axes,\n    errors: dict[int, npt.NDArray[np.float64]],\n    mol: Molecule,\n) -&gt; None:\n    \"\"\"Plot a seaborn swarmplot of the force errors by atom index.\"\"\"\n    import seaborn as sns\n\n    for iteration, force_errors in errors.items():\n        # Create an array of atom indices\n        atom_indices = np.arange(len(force_errors)) % mol.n_atoms\n        df = pd.DataFrame(\n            {\n                \"atom_index\": atom_indices,\n                \"force_error\": np.linalg.norm(force_errors, axis=1),\n                \"iteration\": np.ones_like(atom_indices) * iteration,\n            }\n        )\n        sns.stripplot(\n            x=\"atom_index\",\n            y=\"force_error\",\n            data=df,\n            ax=ax,\n            label=f\"Iteration {iteration}\",\n            alpha=0.4,\n        )\n\n    # Get molecule image\n    mol_image = get_mol_image_with_atom_idxs(mol, width=1800, height=600)\n\n    # Create an inset axes above the main plot for the molecule\n    from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n\n    ax_inset = inset_axes(\n        ax,\n        width=\"400%\",\n        height=\"120%\",\n        loc=\"upper center\",\n        bbox_to_anchor=(0, 1.15, 1, 0.3),\n        bbox_transform=ax.transAxes,\n    )\n    ax_inset.imshow(mol_image)\n    ax_inset.axis(\"off\")\n\n    ax.set_xlabel(\"Atom Index\")\n    ax.set_ylabel(\"Force Error / kcal mol$^{-1}$ \u00c5$^{-1}$\")\n\n    # Deduplicate legend entries\n    handles, labels = ax.get_legend_handles_labels()\n    by_label = dict(zip(labels, handles, strict=False))\n    ax.legend(\n        by_label.values(), by_label.keys(), bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n    )\n</code></pre>"},{"location":"reference/analyse/#bespokefit_smee.analyse.plot_error_statistics","title":"plot_error_statistics","text":"<pre><code>plot_error_statistics(\n    fig: Figure,\n    axs: NDArray[Any],\n    errors: dict[\n        Literal[\"energy_differences\", \"forces_differences\"],\n        dict[int, NDArray[float64]],\n    ],\n) -&gt; None\n</code></pre> <p>Plot the error statistics for the energy and force errors.</p> Source code in <code>bespokefit_smee/analyse.py</code> <pre><code>def plot_error_statistics(\n    fig: Figure,\n    axs: npt.NDArray[Any],\n    errors: dict[\n        Literal[\"energy_differences\", \"forces_differences\"],\n        dict[int, npt.NDArray[np.float64]],\n    ],\n) -&gt; None:\n    \"\"\"Plot the error statistics for the energy and force errors.\"\"\"\n\n    axs = axs.flatten()\n    plot_distributions_of_errors(fig, axs[0], errors[\"energy_differences\"], \"energy\")\n    plot_distributions_of_errors(fig, axs[1], errors[\"forces_differences\"], \"force\")\n    # Hide the legend in the first plot\n    axs[0].legend().set_visible(False)\n\n    # Plot the rmsds of the errors\n    plot_rmse_of_errors(fig, axs[2], errors[\"energy_differences\"], \"energy\")\n    plot_rmse_of_errors(fig, axs[3], errors[\"forces_differences\"], \"force\")\n\n    # Plot the mean errors\n    # plot_mean_errors(fig, axs[4], errors, \"energy\")\n    # plot_mean_errors(fig, axs[5], errors, \"force\")\n\n    # # Plot the standard deviation of the errors\n    plot_sd_of_errors(fig, axs[4], errors[\"energy_differences\"], \"energy\")\n    plot_sd_of_errors(fig, axs[5], errors[\"forces_differences\"], \"force\")\n</code></pre>"},{"location":"reference/analyse/#bespokefit_smee.analyse.analyse_workflow","title":"analyse_workflow","text":"<pre><code>analyse_workflow(\n    workflow_settings: WorkflowSettings,\n) -&gt; None\n</code></pre> <p>Analyse the results of a BespokeFitSMEE workflow.</p> Source code in <code>bespokefit_smee/analyse.py</code> <pre><code>def analyse_workflow(workflow_settings: WorkflowSettings) -&gt; None:\n    \"\"\"Analyse the results of a BespokeFitSMEE workflow.\"\"\"\n\n    with plt.style.context(PLT_STYLE):\n        # Plot the losses\n        path_manager = workflow_settings.get_path_manager()\n        stage = OutputStage(StageKind.PLOTS)\n        path_manager.mk_stage_dir(stage)\n        mol = Molecule.from_smiles(\n            workflow_settings.parameterisation_settings.smiles,\n            allow_undefined_stereo=True,\n        )\n\n        output_paths_by_output_type = path_manager.get_all_output_paths_by_output_type()\n        training_metric_paths = dict(\n            enumerate(output_paths_by_output_type[OutputType.TRAINING_METRICS])\n        )\n        losses = read_losses(training_metric_paths)\n        fig, ax = plt.subplots(figsize=(10, 6))\n        plot_loss(fig, ax, losses)\n        fig.savefig(\n            str(path_manager.get_output_path(stage, OutputType.LOSS_PLOT)),\n            dpi=300,\n            bbox_inches=\"tight\",\n        )\n        plt.close(fig)\n\n        # Plot the errors\n        scatter_paths = dict(enumerate(output_paths_by_output_type[OutputType.SCATTER]))\n        errors = read_errors(scatter_paths)\n        fig, axs = plt.subplots(3, 2, figsize=(13, 18))\n        # TODO: typing below which is ignored\n        plot_error_statistics(fig, axs, errors)  # type: ignore[arg-type]\n        fig.savefig(\n            str(path_manager.get_output_path(stage, OutputType.ERROR_PLOT)),\n            dpi=300,\n            bbox_inches=\"tight\",\n        )\n        plt.close(fig)\n\n        # Plot the correlation plots\n        fig, ax = plt.subplots(1, 1, figsize=(6.5, 6))\n        plot_energy_correlation(\n            fig,\n            ax,\n            errors[\"energy_reference\"],\n            errors[\"energy_predicted\"],\n        )\n        fig.savefig(\n            str(path_manager.get_output_path(stage, OutputType.CORRELATION_PLOT)),\n            dpi=300,\n            bbox_inches=\"tight\",\n        )\n        plt.close(fig)\n\n        # Plot the force error by atom index\n        fig, ax = plt.subplots(1, 1, figsize=(0.5 * mol.n_atoms, 6))\n        plot_force_error_by_atom_idx(fig, ax, errors[\"forces_differences\"], mol)\n        fig.savefig(\n            str(\n                path_manager.get_output_path(\n                    stage, OutputType.FORCE_ERROR_BY_ATOM_INDEX_PLOT\n                )\n            ),\n            dpi=300,\n            bbox_inches=\"tight\",\n        )\n        plt.close(fig)\n\n        # Plot the force field changes\n        ff_paths = load_force_fields(\n            dict(enumerate(output_paths_by_output_type[OutputType.OFFXML]))\n        )\n\n        fig, axs = plot_all_ffs(ff_paths, mol, \"values\")\n        fig.savefig(\n            str(path_manager.get_output_path(stage, OutputType.PARAMETER_VALUES_PLOT)),\n            dpi=300,\n            bbox_inches=\"tight\",\n        )\n        plt.close(fig)\n\n        fig, axs = plot_all_ffs(ff_paths, mol, \"differences\")\n        fig.savefig(\n            str(\n                path_manager.get_output_path(\n                    stage, OutputType.PARAMETER_DIFFERENCES_PLOT\n                )\n            ),\n            dpi=300,\n            bbox_inches=\"tight\",\n        )\n        plt.close(fig)\n</code></pre>"},{"location":"reference/find_torsions/","title":"find_torsions","text":""},{"location":"reference/find_torsions/#bespokefit_smee.find_torsions","title":"find_torsions","text":"<p>Functionality for finding and sampling torsions in a molecule.</p> <p>Functions:</p> <ul> <li> <code>get_single_torsion_by_rot_bond</code>             \u2013              <p>Get a single torsion for each rotatable bond matching the provided SMARTS pattern.</p> </li> <li> <code>get_unwanted_bonds</code>             \u2013              <p>Get a set of unwanted bonds in the molecule based on the provided SMARTS patterns.</p> </li> <li> <code>get_rot_torsions_by_rot_bond</code>             \u2013              <p>Find rotatable torsions in the molecule based on SMARTS patterns.</p> </li> </ul>"},{"location":"reference/find_torsions/#bespokefit_smee.find_torsions.get_single_torsion_by_rot_bond","title":"get_single_torsion_by_rot_bond","text":"<pre><code>get_single_torsion_by_rot_bond(\n    mol: Molecule, smarts: str\n) -&gt; dict[tuple[int, int], tuple[int, int, int, int]]\n</code></pre> <p>Get a single torsion for each rotatable bond matching the provided SMARTS pattern.</p> <p>Parameters:</p> <ul> <li> <code>mol</code>               (<code>Molecule</code>)           \u2013            <p>The molecule to search.</p> </li> <li> <code>smarts</code>               (<code>str</code>)           \u2013            <p>SMARTS pattern to match rotatable bonds. This should specify the entire torsion, not just the rotatable bond.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict of tuple of int to tuple of int</code>           \u2013            <p>A dictionary mapping each rotatable bond (as a tuple of atom indices) to a single torsion (as a tuple of four atom indices).</p> </li> </ul> Source code in <code>bespokefit_smee/find_torsions.py</code> <pre><code>def get_single_torsion_by_rot_bond(\n    mol: Molecule,\n    smarts: str,\n) -&gt; dict[tuple[int, int], tuple[int, int, int, int]]:\n    \"\"\"\n    Get a single torsion for each rotatable bond matching the provided SMARTS pattern.\n\n    Parameters\n    ----------\n    mol : openff.toolkit.topology.Molecule\n        The molecule to search.\n    smarts : str\n        SMARTS pattern to match rotatable bonds. This should specify the entire\n        torsion, not just the rotatable bond.\n\n    Returns\n    -------\n    dict of tuple of int to tuple of int\n        A dictionary mapping each rotatable bond (as a tuple of atom indices) to a single torsion\n        (as a tuple of four atom indices).\n    \"\"\"\n    all_torsions = mol.chemical_environment_matches(smarts, unique=True)\n    torsions_by_rot_bonds = {}\n\n    for torsion in all_torsions:\n        if len(torsion) != 4:\n            raise ValueError(\n                f\"Expected torsion to have 4 atoms, but got {len(torsion)}: {torsion}.\"\n                \" Ensure the SMARTS patterns match full torsions.\"\n            )\n\n        rot_bond = tuple(\n            sorted((torsion[1], torsion[2]))\n        )  # Middle two atoms are the rotatable bond\n        if rot_bond not in torsions_by_rot_bonds:\n            torsions_by_rot_bonds[rot_bond] = torsion\n        else:\n            # If we already have a torsion for this rotatable bond, skip it\n            continue\n\n    return torsions_by_rot_bonds\n</code></pre>"},{"location":"reference/find_torsions/#bespokefit_smee.find_torsions.get_unwanted_bonds","title":"get_unwanted_bonds","text":"<pre><code>get_unwanted_bonds(\n    mol: Molecule, smarts: str\n) -&gt; set[tuple[int, int]]\n</code></pre> <p>Get a set of unwanted bonds in the molecule based on the provided SMARTS patterns.</p> <p>Parameters:</p> <ul> <li> <code>mol</code>               (<code>Molecule</code>)           \u2013            <p>The molecule to search.</p> </li> <li> <code>smarts</code>               (<code>str</code>)           \u2013            <p>SMARTS pattern to match unwanted bonds. This should match only the rotatable bond, not the full torsion.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>set of tuple of int</code>           \u2013            <p>A set of tuples representing the unwanted bonds, where each tuple contains the indices of the two atoms forming the bond.</p> </li> </ul> Source code in <code>bespokefit_smee/find_torsions.py</code> <pre><code>def get_unwanted_bonds(mol: Molecule, smarts: str) -&gt; set[tuple[int, int]]:\n    \"\"\"\n    Get a set of unwanted bonds in the molecule based on the provided SMARTS patterns.\n\n    Parameters\n    ----------\n    mol : openff.toolkit.topology.Molecule\n        The molecule to search.\n    smarts : str\n        SMARTS pattern to match unwanted bonds. This should match only the rotatable bond,\n        not the full torsion.\n\n    Returns\n    -------\n    set of tuple of int\n        A set of tuples representing the unwanted bonds, where each tuple contains the indices of the two\n        atoms forming the bond.\n    \"\"\"\n    bonds = mol.chemical_environment_matches(smarts, unique=True)\n    for bond in bonds:\n        if len(bond) != 2:\n            raise ValueError(\n                f\"Expected bond to have 2 atoms, but got {len(bond)}: {bond}.\"\n                \" Ensure the SMARTS pattern matches only the rotatable bond.\"\n            )\n\n    return {tuple(sorted(bond)) for bond in bonds}\n</code></pre>"},{"location":"reference/find_torsions/#bespokefit_smee.find_torsions.get_rot_torsions_by_rot_bond","title":"get_rot_torsions_by_rot_bond","text":"<pre><code>get_rot_torsions_by_rot_bond(\n    molecule: Molecule,\n    include_smarts: list[str] = _TORSIONS_TO_INCLUDE_SMARTS,\n    exclude_smarts: list[str] = _TORSIONS_TO_EXCLUDE_SMARTS,\n) -&gt; dict[tuple[int, int], tuple[int, int, int, int]]\n</code></pre> <p>Find rotatable torsions in the molecule based on SMARTS patterns.</p> <p>Parameters:</p> <ul> <li> <code>molecule</code>               (<code>Molecule</code>)           \u2013            <p>The molecule to search.</p> </li> <li> <code>include_smarts</code>               (<code>list of str</code>, default:                   <code>_TORSIONS_TO_INCLUDE_SMARTS</code> )           \u2013            <p>List of SMARTS patterns to include. Defaults to _TORSIONS_TO_INCLUDE_SMARTS. These should match the entire torsion, not just the rotatable bond.</p> </li> <li> <code>exclude_smarts</code>               (<code>list of str</code>, default:                   <code>_TORSIONS_TO_EXCLUDE_SMARTS</code> )           \u2013            <p>List of SMARTS patterns to exclude. Defaults to _TORSIONS_TO_EXCLUDE_SMARTS. These should match only the rotatable bond, not the full torsion.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict of tuple of int to tuple of int</code>           \u2013            <p>A dictionary mapping each rotatable bond (as a tuple of atom indices) to a single torsion (as a tuple of four atom indices).</p> </li> </ul> Source code in <code>bespokefit_smee/find_torsions.py</code> <pre><code>def get_rot_torsions_by_rot_bond(\n    molecule: Molecule,\n    include_smarts: list[str] = _TORSIONS_TO_INCLUDE_SMARTS,\n    exclude_smarts: list[str] = _TORSIONS_TO_EXCLUDE_SMARTS,\n) -&gt; dict[tuple[int, int], tuple[int, int, int, int]]:\n    \"\"\"\n    Find rotatable torsions in the molecule based on SMARTS patterns.\n\n    Parameters\n    ----------\n    molecule : openff.toolkit.topology.Molecule\n        The molecule to search.\n    include_smarts : list of str, optional\n        List of SMARTS patterns to include. Defaults to _TORSIONS_TO_INCLUDE_SMARTS.\n        These should match the entire torsion, not just the rotatable bond.\n    exclude_smarts : list of str, optional\n        List of SMARTS patterns to exclude. Defaults to _TORSIONS_TO_EXCLUDE_SMARTS.\n        These should match only the rotatable bond, not the full torsion.\n\n    Returns\n    -------\n    dict of tuple of int to tuple of int\n        A dictionary mapping each rotatable bond (as a tuple of atom indices) to a single torsion\n        (as a tuple of four atom indices).\n    \"\"\"\n\n    torsions_by_rot_bonds = {}\n\n    for smarts in include_smarts:\n        torsions = get_single_torsion_by_rot_bond(molecule, smarts)\n        torsions_by_rot_bonds.update(torsions)\n\n    for smarts in exclude_smarts:\n        unwanted_bonds = get_unwanted_bonds(molecule, smarts)\n        print(f\"Excluding unwanted bonds: {unwanted_bonds}\")\n        for rot_bond in unwanted_bonds:\n            torsions_by_rot_bonds.pop(rot_bond, None)\n\n    return torsions_by_rot_bonds\n</code></pre>"},{"location":"reference/loss_functions/","title":"loss_functions","text":""},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions","title":"loss_functions","text":"<p>Loss functions for tuning the forcefield</p> <p>Functions:</p> <ul> <li> <code>prediction_loss</code>             \u2013              <p>Predict the loss function for a guess forcefield against a dataset.</p> </li> <li> <code>get_regularised_parameter_idxs</code>             \u2013              <p>Get the indexes of the parameters to regularise (these idxs apply to the trainable_parameters,</p> </li> <li> <code>compute_regularisation_penalty</code>             \u2013              <p>Compute regularisation penalty</p> </li> <li> <code>get_loss_closure_fn</code>             \u2013              <p>Return a default closure function</p> </li> <li> <code>predict</code>             \u2013              <p>Predict the relative energies [kcal/mol] and forces [kcal/mol/\u00c5] of a dataset.</p> </li> </ul>"},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions.prediction_loss","title":"prediction_loss","text":"<pre><code>prediction_loss(\n    dataset: Dataset,\n    trainable: Trainable,\n    trainable_parameters: Tensor,\n    initial_parameters: Tensor,\n    topology: TensorTopology,\n    loss_force_weight: float,\n    regularisation_settings: RegularisationSettings,\n    device_type: str,\n) -&gt; Tensor\n</code></pre> <p>Predict the loss function for a guess forcefield against a dataset.</p> <p>Args:     dataset: The dataset to predict the energies and forces of.     trainable: The trainable object containing the force field.     trainable_parameters: The parameters to be optimized.     initial_parameters: The initial parameters before training.     topologies: The topologies of the molecules in the dataset.     loss_force_weight: Weight for the force loss term.     regularisation_settings: Settings for regularisation.     device_type: The device type (e.g., 'cpu' or 'cuda').</p> <p>Returns:     Loss value.</p> Source code in <code>bespokefit_smee/loss_functions.py</code> <pre><code>def prediction_loss(\n    dataset: datasets.Dataset,\n    trainable: descent.train.Trainable,\n    trainable_parameters: torch.Tensor,\n    initial_parameters: torch.Tensor,\n    topology: smee.TensorTopology,\n    loss_force_weight: float,\n    regularisation_settings: RegularisationSettings,\n    device_type: str,\n) -&gt; torch.Tensor:\n    \"\"\"Predict the loss function for a guess forcefield against a dataset.\n\n    Args:\n        dataset: The dataset to predict the energies and forces of.\n        trainable: The trainable object containing the force field.\n        trainable_parameters: The parameters to be optimized.\n        initial_parameters: The initial parameters before training.\n        topologies: The topologies of the molecules in the dataset.\n        loss_force_weight: Weight for the force loss term.\n        regularisation_settings: Settings for regularisation.\n        device_type: The device type (e.g., 'cpu' or 'cuda').\n\n    Returns:\n        Loss value.\n    \"\"\"\n    energy_ref_all, energy_pred_all, forces_ref_all, forces_pred_all = predict(\n        dataset,\n        trainable.to_force_field(trainable_parameters),\n        {dataset[0][\"smiles\"]: topology},\n        device_type=device_type,\n        normalize=False,\n    )\n    # Loss as the JS-divergence between the two distributions\n    # beta = 1.987204259e-3 * 500  # kcal/mol/K\n\n    # def _kl_div(p: torch.Tensor, q: torch.Tensor) -&gt; torch.Tensor:\n    #     return (p * (p / q).clamp(min=1e-10).log()).sum()\n\n    # distribution_ref = torch.exp(-energy_ref_all / beta)\n    # distribution_ref = distribution_ref / distribution_ref.sum()\n    # distribution_pred = torch.exp(-energy_pred_all / beta)\n    # distribution_pred = distribution_pred / distribution_pred.sum()\n    # m = 0.5 * (distribution_ref + distribution_pred)\n    # loss_distribution = 0.5 * (\n    #     _kl_div(distribution_ref, m) + _kl_div(distribution_pred, m)\n    # )\n    # return loss_distribution\n\n    loss_energy: torch.Tensor = ((energy_ref_all - energy_pred_all) ** 2).mean()\n    loss_forces: torch.Tensor = ((forces_ref_all - forces_pred_all) ** 2).mean()\n\n    # Regularisation penalty\n    regularisation_pentalty = compute_regularisation_penalty(\n        trainable, trainable_parameters, initial_parameters, regularisation_settings\n    )\n\n    # logger.info(\n    #     f\"Loss: Energy={loss_energy.item():.4f} Forces={loss_forces.item():.4f} Reg={regularisation_pentalty.item():.4f}\"\n    # )\n\n    return loss_energy + loss_forces * loss_force_weight + regularisation_pentalty\n</code></pre>"},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions.get_regularised_parameter_idxs","title":"get_regularised_parameter_idxs","text":"<pre><code>get_regularised_parameter_idxs(\n    trainable: Trainable, cols: dict[ValenceType, list[str]]\n) -&gt; Tensor\n</code></pre> <p>Get the indexes of the parameters to regularise (these idxs apply to the trainable_parameters, rather than the full set of parameters in the force field).</p> <p>Args:     trainable: The trainable object.     cols: Dictionary mapping valence types to parameter columns to regularise.</p> <p>Returns:     Tensor of indexes of parameters to regularise.</p> Source code in <code>bespokefit_smee/loss_functions.py</code> <pre><code>def get_regularised_parameter_idxs(\n    trainable: descent.train.Trainable,\n    cols: dict[ValenceType, list[str]],\n) -&gt; torch.Tensor:\n    \"\"\"Get the indexes of the parameters to regularise (these idxs apply to the trainable_parameters,\n    rather than the full set of parameters in the force field).\n\n    Args:\n        trainable: The trainable object.\n        cols: Dictionary mapping valence types to parameter columns to regularise.\n\n    Returns:\n        Tensor of indexes of parameters to regularise.\n    \"\"\"\n    idxs: list[int] = []\n    col_offset = 0\n\n    potentials = [\n        trainable._force_field.potentials_by_type[potential_type]\n        for potential_type in trainable._param_types\n    ]\n\n    for potential_type, potential in zip(\n        trainable._param_types, potentials, strict=True\n    ):\n        potential_cols = potential.parameter_cols\n\n        potential_values = potential.parameters.detach().clone()\n        potential_values_flat = potential_values.flatten()\n\n        n_rows = len(potential_values)\n        unfrozen_rows = set(range(n_rows))\n\n        if potential_type in cols:\n            assert len({*cols[potential_type]} - {*potential_cols}) == 0, (\n                f\"unknown columns: {potential_cols}\"\n            )\n\n            idxs.extend(\n                col_offset + col_idx + row_idx * potential_values.shape[-1]\n                for row_idx in range(n_rows)\n                if row_idx in unfrozen_rows\n                for col_idx, col in enumerate(potential_cols)\n                if col in cols[potential_type]\n            )\n\n        col_offset += len(potential_values_flat)\n\n    # Get the indices of the regularised values in the unfrozen idxs of the trainable\n    trained_and_regularised_idxs = set()\n    for idx_in_unfrozen, unfrozen_idx in enumerate(trainable._unfrozen_idxs):\n        if unfrozen_idx in idxs:\n            trained_and_regularised_idxs.add(idx_in_unfrozen)\n\n    return smee.utils.tensor_like(\n        torch.tensor(\n            list(trained_and_regularised_idxs),\n            dtype=torch.long,\n        ),\n        trainable._unfrozen_idxs,\n    )\n</code></pre>"},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions.compute_regularisation_penalty","title":"compute_regularisation_penalty","text":"<pre><code>compute_regularisation_penalty(\n    trainable: Trainable,\n    trainable_parameters: Tensor,\n    initial_parameters: Tensor,\n    regularisation_settings: RegularisationSettings,\n) -&gt; Tensor\n</code></pre> <p>Compute regularisation penalty</p> Source code in <code>bespokefit_smee/loss_functions.py</code> <pre><code>def compute_regularisation_penalty(\n    trainable: descent.train.Trainable,\n    trainable_parameters: torch.Tensor,\n    initial_parameters: torch.Tensor,\n    regularisation_settings: RegularisationSettings,\n) -&gt; torch.Tensor:\n    \"\"\"Compute regularisation penalty\"\"\"\n    penalty = torch.tensor(0.0, device=trainable_parameters.device)\n\n    # Get the idxs of the parameters to regularise\n    if hasattr(trainable, \"regularised_parameter_idxs\"):\n        regularised_parameter_idxs = trainable.regularised_parameter_idxs\n    else:\n        regularised_parameter_idxs = get_regularised_parameter_idxs(\n            trainable, regularisation_settings.parameters\n        )\n        trainable.regularised_parameter_idxs = regularised_parameter_idxs\n\n    if regularisation_settings.regularisation_value == \"initial\":\n        target = initial_parameters[regularised_parameter_idxs]\n    elif regularisation_settings.regularisation_value == \"zero\":\n        target = torch.zeros_like(trainable_parameters[regularised_parameter_idxs])\n    else:\n        raise NotImplementedError(\n            f\"regularisation value \"\n            f\"{regularisation_settings.regularisation_value} not implemented\"\n        )\n\n    # L2 regularisation on all parameters\n    penalty += (\n        (trainable_parameters[regularised_parameter_idxs] - target) ** 2\n    ).mean() * regularisation_settings.regularisation_strength\n\n    return penalty\n</code></pre>"},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions.get_loss_closure_fn","title":"get_loss_closure_fn","text":"<pre><code>get_loss_closure_fn(\n    trainable: Trainable,\n    initial_x: Tensor,\n    topology: TensorTopology,\n    dataset: Dataset,\n    regularisation_settings: RegularisationSettings,\n) -&gt; ClosureFn\n</code></pre> <p>Return a default closure function</p> <p>Args:     trainable: The trainable object.     initial_x: The initial parameters before training.     topology: The topology of the system.     dataset: The dataset to use for the loss function.     regularisation_settings: Settings for regularisation.</p> <p>Returns:     A closure function that takes a tensor and returns the loss, gradient (if requested), and hessian (if requested).</p> Source code in <code>bespokefit_smee/loss_functions.py</code> <pre><code>def get_loss_closure_fn(\n    trainable: descent.train.Trainable,\n    initial_x: torch.Tensor,\n    topology: smee.TensorTopology,\n    dataset: datasets.Dataset,\n    regularisation_settings: RegularisationSettings,\n) -&gt; descent.optim.ClosureFn:\n    \"\"\"\n    Return a default closure function\n\n    Args:\n        trainable: The trainable object.\n        initial_x: The initial parameters before training.\n        topology: The topology of the system.\n        dataset: The dataset to use for the loss function.\n        regularisation_settings: Settings for regularisation.\n\n    Returns:\n        A closure function that takes a tensor and returns the loss, gradient (if requested), and hessian (if requested).\n    \"\"\"\n\n    def closure_fn(\n        x: torch.Tensor,\n        compute_gradient: bool,\n        compute_hessian: bool,\n    ) -&gt; tuple[torch.Tensor, torch.Tensor | None, torch.Tensor | None]:\n        loss, gradient, hessian = (\n            torch.zeros(size=(1,), device=x.device.type),\n            None,\n            None,\n        )\n\n        def loss_fn(_x: torch.Tensor) -&gt; torch.Tensor:\n            \"\"\"Compute the loss function for the given trainable parameters.\"\"\"\n            ff = trainable.to_force_field(_x)\n            y_ref, y_pred = predict(\n                dataset,\n                ff,\n                {dataset[0][\"smiles\"]: topology},\n                device_type=x.device.type,\n                normalize=False,\n            )[:2]\n            loss: torch.Tensor = ((y_pred - y_ref) ** 2).mean()\n\n            regularisation_penalty = compute_regularisation_penalty(\n                trainable, _x, initial_x, regularisation_settings\n            )\n            loss += regularisation_penalty\n\n            return loss\n\n        loss += loss_fn(x)\n\n        if compute_hessian:\n            hessian = torch.autograd.functional.hessian(  # type: ignore[no-untyped-call]\n                loss_fn, x, vectorize=True, create_graph=False\n            ).detach()\n        if compute_gradient:\n            (gradient,) = torch.autograd.grad(loss, x, create_graph=False)\n            gradient = gradient.detach()\n\n        return loss, gradient, hessian\n\n    return closure_fn\n</code></pre>"},{"location":"reference/loss_functions/#bespokefit_smee.loss_functions.predict","title":"predict","text":"<pre><code>predict(\n    dataset: Dataset,\n    force_field: TensorForceField,\n    topologies: dict[str, TensorTopology],\n    reference: Literal[\"mean\", \"min\"] = \"mean\",\n    normalize: bool = True,\n    device_type: str = \"cpu\",\n) -&gt; tuple[Tensor, Tensor, Tensor, Tensor]\n</code></pre> <p>Predict the relative energies [kcal/mol] and forces [kcal/mol/\u00c5] of a dataset.</p> <p>Args:     dataset: The dataset to predict the energies and forces of.     force_field: The force field to use to predict the energies and forces.     topologies: The topologies of the molecules in the dataset. Each key should be         a fully indexed SMILES string.     reference: The reference energy to compute the relative energies with respect         to. This should be either the \"mean\" energy of all conformers, or the         energy of the conformer with the lowest reference energy (\"min\").     normalize: Whether to scale the relative energies by <code>1/sqrt(n_confs_i)</code>         and the forces by <code>1/sqrt(n_confs_i * n_atoms_per_conf_i * 3)</code> This         is useful when wanting to compute the MSE per entry.</p> <p>Returns:     The predicted and reference relative energies [kcal/mol] with     <code>shape=(n_confs,)</code>, and predicted and reference forces [kcal/mol/\u00c5] with     <code>shape=(n_confs * n_atoms_per_conf, 3)</code>.</p> Source code in <code>bespokefit_smee/loss_functions.py</code> <pre><code>def predict(\n    dataset: datasets.Dataset,\n    force_field: smee.TensorForceField,\n    topologies: dict[str, smee.TensorTopology],\n    reference: typing.Literal[\"mean\", \"min\"] = \"mean\",\n    normalize: bool = True,\n    device_type: str = \"cpu\",\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Predict the relative energies [kcal/mol] and forces [kcal/mol/\u00c5] of a dataset.\n\n    Args:\n        dataset: The dataset to predict the energies and forces of.\n        force_field: The force field to use to predict the energies and forces.\n        topologies: The topologies of the molecules in the dataset. Each key should be\n            a fully indexed SMILES string.\n        reference: The reference energy to compute the relative energies with respect\n            to. This should be either the \"mean\" energy of all conformers, or the\n            energy of the conformer with the lowest reference energy (\"min\").\n        normalize: Whether to scale the relative energies by ``1/sqrt(n_confs_i)``\n            and the forces by ``1/sqrt(n_confs_i * n_atoms_per_conf_i * 3)`` This\n            is useful when wanting to compute the MSE per entry.\n\n    Returns:\n        The predicted and reference relative energies [kcal/mol] with\n        ``shape=(n_confs,)``, and predicted and reference forces [kcal/mol/\u00c5] with\n        ``shape=(n_confs * n_atoms_per_conf, 3)``.\n    \"\"\"\n    energy_ref_all, energy_pred_all = [], []\n    forces_ref_all, forces_pred_all = [], []\n\n    for entry in dataset:\n        smiles = entry[\"smiles\"]\n\n        energy_ref = entry[\"energy\"].to(device_type)\n        forces_ref = entry[\"forces\"].reshape(len(energy_ref), -1, 3).to(device_type)\n\n        coords_flat = smee.utils.tensor_like(\n            entry[\"coords\"], force_field.potentials[0].parameters\n        )\n\n        coords = (\n            (coords_flat.reshape(len(energy_ref), -1, 3))\n            .to(device_type)\n            .detach()\n            .requires_grad_(True)\n        )\n        topology = topologies[smiles]\n\n        energy_pred = smee.compute_energy(topology, force_field, coords)\n        forces_pred = -torch.autograd.grad(\n            energy_pred.sum(),\n            coords,\n            create_graph=True,\n            retain_graph=True,\n            allow_unused=True,\n        )[0]\n\n        if reference.lower() == \"mean\":\n            energy_ref_0 = energy_ref.mean()\n            energy_pred_0 = energy_pred.mean()\n        elif reference.lower() == \"min\":\n            min_idx = energy_ref.argmin()\n\n            energy_ref_0 = energy_ref[min_idx]\n            energy_pred_0 = energy_pred[min_idx]\n        else:\n            raise NotImplementedError(f\"invalid reference energy {reference}\")\n\n        scale_energy, scale_forces = 1.0, 1.0\n\n        if normalize:\n            scale_energy = 1.0 / torch.sqrt(torch.tensor(energy_pred.numel()))\n            scale_forces = 1.0 / torch.sqrt(torch.tensor(forces_pred.numel()))\n\n        energy_ref_all.append(scale_energy * (energy_ref - energy_ref_0))\n        forces_ref_all.append(scale_forces * forces_ref.reshape(-1, 3))\n\n        energy_pred_all.append(scale_energy * (energy_pred - energy_pred_0))\n        forces_pred_all.append(scale_forces * forces_pred.reshape(-1, 3))\n\n    energy_pred_all_tensor = torch.cat(energy_pred_all)\n    forces_pred_all_tensor = torch.cat(forces_pred_all)\n\n    energy_ref_all_tensor = torch.cat(energy_ref_all)\n    energy_ref_all_tensor = smee.utils.tensor_like(\n        energy_ref_all_tensor, energy_pred_all_tensor\n    )\n\n    forces_ref_all_tensor = torch.cat(forces_ref_all)\n    forces_ref_all_tensor = smee.utils.tensor_like(\n        forces_ref_all_tensor, forces_pred_all_tensor\n    )\n\n    return (\n        energy_ref_all_tensor,\n        energy_pred_all_tensor,\n        forces_ref_all_tensor,\n        forces_pred_all_tensor,\n    )\n</code></pre>"},{"location":"reference/metadynamics/","title":"metadynamics","text":""},{"location":"reference/metadynamics/#bespokefit_smee.metadynamics","title":"metadynamics","text":"<p>The code below is slightly modified from the original in OpenMM at https://github.com/openmm/openmm/blob/master/wrappers/python/openmm/app/metadynamics.py. The original code is licensed under the MIT License and is reproduced here:</p> <p>metadynamics.py: Well-tempered metadynamics</p> <p>This is part of the OpenMM molecular simulation toolkit originating from Simbios, the NIH National Center for Physics-Based Simulation of Biological Structures at Stanford, funded under the NIH Roadmap for Medical Research, grant U54 GM072970. See https://simtk.org.</p> <p>Portions copyright (c) 2018-2019 Stanford University and the Authors. Authors: Peter Eastman</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS, CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p> <p>Classes:</p> <ul> <li> <code>Metadynamics</code>           \u2013            <p>Performs metadynamics.</p> </li> </ul>"},{"location":"reference/metadynamics/#bespokefit_smee.metadynamics.Metadynamics","title":"Metadynamics","text":"<pre><code>Metadynamics(\n    system,\n    variables,\n    temperature,\n    biasFactor,\n    height,\n    frequency,\n    saveFrequency=None,\n    biasDir=None,\n    independentCVs=False,\n)\n</code></pre> <p>               Bases: <code>object</code></p> <p>Performs metadynamics.</p> <p>This class implements well-tempered metadynamics, as described in Barducci et al., \"Well-Tempered Metadynamics: A Smoothly Converging and Tunable Free-Energy Method\" (https://doi.org/10.1103/PhysRevLett.100.020603).  You specify from one to three collective variables whose sampling should be accelerated.  A biasing force that depends on the collective variables is added to the simulation.  Initially the bias is zero.  As the simulation runs, Gaussian bumps are periodically added to the bias at the current location of the simulation.  This pushes the simulation away from areas it has already explored, encouraging it to sample other regions.  At the end of the simulation, the bias function can be used to calculate the system's free energy as a function of the collective variables.</p> <p>To use the class you create a Metadynamics object, passing to it the System you want to simulate and a list of BiasVariable objects defining the collective variables. It creates a biasing force and adds it to the System.  You then run the simulation as usual, but call step() on the Metadynamics object instead of on the Simulation.</p> <p>You can optionally specify a directory on disk where the current bias function should periodically be written.  In addition, it loads biases from any other files in the same directory and includes them in the simulation.  It loads files when the Metqdynamics object is first created, and also checks for any new files every time it updates its own bias on disk.</p> <p>This serves two important functions.  First, it lets you stop a metadynamics run and resume it later.  When you begin the new simulation, it will load the biases computed in the earlier simulation and continue adding to them.  Second, it provides an easy way to parallelize metadynamics sampling across many computers.  Just point all of them to a shared directory on disk.  Each process will save its biases to that directory, and also load in and apply the biases added by other processes.</p> <p>Parameters:</p> <ul> <li> <code>system</code>           \u2013            <p>the System to simulate.  A CustomCVForce implementing the bias is created and added to the System.</p> </li> <li> <code>variables</code>           \u2013            <p>the collective variables to sample</p> </li> <li> <code>temperature</code>           \u2013            <p>the temperature at which the simulation is being run.  This is used in computing the free energy.</p> </li> <li> <code>biasFactor</code>           \u2013            <p>used in scaling the height of the Gaussians added to the bias.  The collective variables are sampled as if the effective temperature of the simulation were temperature*biasFactor.</p> </li> <li> <code>height</code>           \u2013            <p>the initial height of the Gaussians to add</p> </li> <li> <code>frequency</code>           \u2013            <p>the interval in time steps at which Gaussians should be added to the bias potential</p> </li> <li> <code>saveFrequency</code>           \u2013            <p>the interval in time steps at which to write out the current biases to disk.  At the same time it writes biases, it also checks for updated biases written by other processes and loads them in.  This must be a multiple of frequency.</p> </li> <li> <code>biasDir</code>           \u2013            <p>the directory to which biases should be written, and from which biases written by other processes should be loaded</p> </li> <li> <code>independentCVs</code>           \u2013            <p>whether to treat each collective variable independently or not - if True, the collective variables are treated as independent, and the bias is added to each variable separately.  If False, the collective variables are treated as dependent, and the bias is added to the joint distribution of all variables.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>step</code>             \u2013              <p>Advance the simulation by integrating a specified number of time steps.</p> </li> <li> <code>getFreeEnergy</code>             \u2013              <p>Get the free energy of the system as a function of the collective variables.</p> </li> <li> <code>getCollectiveVariables</code>             \u2013              <p>Get the current values of all collective variables in a Simulation.</p> </li> </ul> Source code in <code>bespokefit_smee/metadynamics.py</code> <pre><code>def __init__(\n    self,\n    system,\n    variables,\n    temperature,\n    biasFactor,\n    height,\n    frequency,\n    saveFrequency=None,\n    biasDir=None,\n    independentCVs=False,\n):\n    \"\"\"Create a Metadynamics object.\n\n    Parameters\n    ----------\n    system: System\n        the System to simulate.  A CustomCVForce implementing the bias is created and\n        added to the System.\n    variables: list of BiasVariables\n        the collective variables to sample\n    temperature: temperature\n        the temperature at which the simulation is being run.  This is used in computing\n        the free energy.\n    biasFactor: float\n        used in scaling the height of the Gaussians added to the bias.  The collective\n        variables are sampled as if the effective temperature of the simulation were\n        temperature*biasFactor.\n    height: energy\n        the initial height of the Gaussians to add\n    frequency: int\n        the interval in time steps at which Gaussians should be added to the bias potential\n    saveFrequency: int (optional)\n        the interval in time steps at which to write out the current biases to disk.  At\n        the same time it writes biases, it also checks for updated biases written by other\n        processes and loads them in.  This must be a multiple of frequency.\n    biasDir: str (optional)\n        the directory to which biases should be written, and from which biases written by\n        other processes should be loaded\n    independentCVs: bool\n        whether to treat each collective variable independently or not - if True, the\n        collective variables are treated as independent, and the bias is added to each\n        variable separately.  If False, the collective variables are treated as dependent,\n        and the bias is added to the joint distribution of all variables.\n    \"\"\"\n    if not unit.is_quantity(temperature):\n        temperature = temperature * unit.kelvin\n    if not unit.is_quantity(height):\n        height = height * unit.kilojoules_per_mole\n    if biasFactor &lt;= 1.0:\n        raise ValueError(\"biasFactor must be &gt; 1\")\n    if (saveFrequency is None and biasDir is not None) or (\n        saveFrequency is not None and biasDir is None\n    ):\n        raise ValueError(\"Must specify both saveFrequency and biasDir\")\n    if saveFrequency is not None and (\n        saveFrequency &lt; frequency or saveFrequency % frequency != 0\n    ):\n        raise ValueError(\"saveFrequency must be a multiple of frequency\")\n    self.variables = variables\n    self.temperature = temperature\n    self.biasFactor = biasFactor\n    self.height = height\n    self.frequency = frequency\n    self.biasDir = biasDir\n    self.saveFrequency = saveFrequency\n    self._id = np.random.randint(0x7FFFFFFF)\n    self._saveIndex = 0\n    self._independentCVs = independentCVs\n    if self._independentCVs:\n        # For the moment, only allow equal number of grid points for all variables\n        gridWidth = variables[0].gridWidth\n        if not all(v.gridWidth == gridWidth for v in variables):\n            raise ValueError(\n                \"All variables must have the same number of grid points when independentCVs is True\"\n            )\n        self._selfBias = np.zeros((len(variables), gridWidth))\n        self._totalBias = np.zeros((len(variables), gridWidth))\n\n    else:\n        self._selfBias = np.zeros(tuple(v.gridWidth for v in reversed(variables)))\n        self._totalBias = np.zeros(tuple(v.gridWidth for v in reversed(variables)))\n    self._loadedBiases = {}\n    self._syncWithDisk()\n    self._deltaT = temperature * (biasFactor - 1)\n    varNames = [\"cv%d\" % i for i in range(len(variables))]\n    if self._independentCVs:\n        self._force = mm.CustomCVForce(\n            \" + \".join(f\"table{i}({name})\" for i, name in enumerate(varNames))\n        )\n    else:\n        self._force = mm.CustomCVForce(\"table(%s)\" % \", \".join(varNames))\n    for name, var in zip(varNames, variables, strict=False):\n        self._force.addCollectiveVariable(name, var.force)\n    self._widths = [v.gridWidth for v in variables]\n    self._limits = sum(([v.minValue, v.maxValue] for v in variables), [])\n    numPeriodics = sum(v.periodic for v in variables)\n    if numPeriodics not in [0, len(variables)]:\n        raise ValueError(\n            \"Metadynamics cannot handle mixed periodic/non-periodic variables\"\n        )\n    periodic = numPeriodics == len(variables)\n\n    if self._independentCVs:\n        self._tables = []\n\n        for i, _ in enumerate(variables):\n            table = mm.Continuous1DFunction(\n                self._totalBias[i].flatten(),\n                self._limits[i * 2],\n                self._limits[i * 2 + 1],\n                periodic,\n            )\n\n            self._tables.append(table)\n\n            self._force.addTabulatedFunction(\"table%d\" % i, table)\n\n    else:\n        if len(variables) == 1:\n            self._table = mm.Continuous1DFunction(\n                self._totalBias.flatten(), *self._limits, periodic\n            )\n        elif len(variables) == 2:\n            self._table = mm.Continuous2DFunction(\n                *self._widths, self._totalBias.flatten(), *self._limits, periodic\n            )\n        elif len(variables) == 3:\n            self._table = mm.Continuous3DFunction(\n                *self._widths, self._totalBias.flatten(), *self._limits, periodic\n            )\n        else:\n            raise ValueError(\n                \"Metadynamics requires 1, 2, or 3 collective variables\"\n            )\n\n        self._force.addTabulatedFunction(\"table\", self._table)\n\n    freeGroups = set(range(32)) - {\n        force.getForceGroup() for force in system.getForces()\n    }\n    if len(freeGroups) == 0:\n        raise RuntimeError(\n            \"Cannot assign a force group to the metadynamics force. \"\n            \"The maximum number (32) of the force groups is already used.\"\n        )\n    self._force.setForceGroup(max(freeGroups))\n    system.addForce(self._force)\n</code></pre>"},{"location":"reference/metadynamics/#bespokefit_smee.metadynamics.Metadynamics.step","title":"step","text":"<pre><code>step(simulation, steps)\n</code></pre> <p>Advance the simulation by integrating a specified number of time steps.</p> <p>Parameters:</p> <ul> <li> <code>simulation</code>           \u2013            <p>the Simulation to advance</p> </li> <li> <code>steps</code>           \u2013            <p>the number of time steps to integrate</p> </li> </ul> Source code in <code>bespokefit_smee/metadynamics.py</code> <pre><code>def step(self, simulation, steps):\n    \"\"\"Advance the simulation by integrating a specified number of time steps.\n\n    Parameters\n    ----------\n    simulation: Simulation\n        the Simulation to advance\n    steps: int\n        the number of time steps to integrate\n    \"\"\"\n    stepsToGo = steps\n    forceGroup = self._force.getForceGroup()\n    while stepsToGo &gt; 0:\n        nextSteps = stepsToGo\n        if simulation.currentStep % self.frequency == 0:\n            nextSteps = min(nextSteps, self.frequency)\n        else:\n            nextSteps = min(\n                nextSteps, self.frequency - simulation.currentStep % self.frequency\n            )\n        simulation.step(nextSteps)\n        if simulation.currentStep % self.frequency == 0:\n            position = self._force.getCollectiveVariableValues(simulation.context)\n            energy = simulation.context.getState(\n                energy=True, groups={forceGroup}\n            ).getPotentialEnergy()\n            height = self.height * np.exp(\n                -energy / (unit.MOLAR_GAS_CONSTANT_R * self._deltaT)\n            )\n            self._addGaussian(position, height, simulation.context)\n        if (\n            self.saveFrequency is not None\n            and simulation.currentStep % self.saveFrequency == 0\n        ):\n            self._syncWithDisk()\n        stepsToGo -= nextSteps\n</code></pre>"},{"location":"reference/metadynamics/#bespokefit_smee.metadynamics.Metadynamics.getFreeEnergy","title":"getFreeEnergy","text":"<pre><code>getFreeEnergy()\n</code></pre> <p>Get the free energy of the system as a function of the collective variables.</p> <p>The result is returned as a N-dimensional NumPy array, where N is the number of collective variables.  The values are in kJ/mole.  The i'th position along an axis corresponds to minValue + i*(maxValue-minValue)/gridWidth.</p> Source code in <code>bespokefit_smee/metadynamics.py</code> <pre><code>def getFreeEnergy(self):\n    \"\"\"Get the free energy of the system as a function of the collective variables.\n\n    The result is returned as a N-dimensional NumPy array, where N is the number of collective\n    variables.  The values are in kJ/mole.  The i'th position along an axis corresponds to\n    minValue + i*(maxValue-minValue)/gridWidth.\n    \"\"\"\n    return (\n        -((self.temperature + self._deltaT) / self._deltaT)\n        * self._totalBias\n        * unit.kilojoules_per_mole\n    )\n</code></pre>"},{"location":"reference/metadynamics/#bespokefit_smee.metadynamics.Metadynamics.getCollectiveVariables","title":"getCollectiveVariables","text":"<pre><code>getCollectiveVariables(simulation)\n</code></pre> <p>Get the current values of all collective variables in a Simulation.</p> Source code in <code>bespokefit_smee/metadynamics.py</code> <pre><code>def getCollectiveVariables(self, simulation):\n    \"\"\"Get the current values of all collective variables in a Simulation.\"\"\"\n    return self._force.getCollectiveVariableValues(simulation.context)\n</code></pre>"},{"location":"reference/mlp/","title":"mlp","text":""},{"location":"reference/mlp/#bespokefit_smee.mlp","title":"mlp","text":"<p>Functionality for creating Open</p> <p>Functions:</p> <ul> <li> <code>load_egret_1</code>             \u2013              <p>Load the Egret-1 MLPotential from local package resources.</p> </li> <li> <code>get_mlp</code>             \u2013              <p>Get the MLPotential model based on the specified model name.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>AvailableModels</code>           \u2013            <p>Available MLPotential models.</p> </li> </ul>"},{"location":"reference/mlp/#bespokefit_smee.mlp.AvailableModels","title":"AvailableModels  <code>module-attribute</code>","text":"<pre><code>AvailableModels = Literal[\n    \"mace-off23-small\",\n    \"mace-off23-medium\",\n    \"mace-off23-large\",\n    \"egret-1\",\n    \"aimnet2_b973c_d3_ens\",\n    \"aimnet2_wb97m_d3_ens\",\n]\n</code></pre> <p>Available MLPotential models.</p>"},{"location":"reference/mlp/#bespokefit_smee.mlp.load_egret_1","title":"load_egret_1","text":"<pre><code>load_egret_1() -&gt; MLPotential\n</code></pre> <p>Load the Egret-1 MLPotential from local package resources.</p> Source code in <code>bespokefit_smee/mlp.py</code> <pre><code>def load_egret_1() -&gt; MLPotential:\n    \"\"\"Load the Egret-1 MLPotential from local package resources.\"\"\"\n    filename = \"EGRET_1.model\"\n    with resources.path(\"bespokefit_smee.models\", filename) as model_path:\n        return MLPotential(\"mace\", modelPath=str(model_path))\n</code></pre>"},{"location":"reference/mlp/#bespokefit_smee.mlp.get_mlp","title":"get_mlp","text":"<pre><code>get_mlp(model: AvailableModels) -&gt; MLPotential\n</code></pre> <p>Get the MLPotential model based on the specified model name.</p> Source code in <code>bespokefit_smee/mlp.py</code> <pre><code>def get_mlp(model: AvailableModels) -&gt; MLPotential:\n    \"\"\"Get the MLPotential model based on the specified model name.\"\"\"\n\n    if model not in get_args(AvailableModels):\n        raise ValueError(\n            f\"Invalid model name: {model}. Available models are: {get_args(AvailableModels)}\"\n        )\n\n    if model not in _cache:\n        if model in aimnet2._AVAILABLE_MODELS:\n            # Ensure AIMNet2 models registered\n            aimnet2._register_aimnet2_potentials()\n        if model == \"egret-1\":\n            _cache[model] = load_egret_1()\n        else:\n            _cache[model] = MLPotential(model)\n\n    return _cache[model]\n</code></pre>"},{"location":"reference/msm/","title":"msm","text":""},{"location":"reference/msm/#bespokefit_smee.msm","title":"msm","text":"<p>Functionality for applying the modified Seminario method.</p> <p>Functions:</p> <ul> <li> <code>apply_msm</code>             \u2013              <p>Generate modified Seminario parameters for the bond and angle terms in the</p> </li> <li> <code>unit_normal_vector</code>             \u2013              <p>Return a unit vector perpendicular to the two input vectors</p> </li> <li> <code>modSem_projection</code>             \u2013              <p>Return a spring constant projected out of a partial hessian onto a unit vector</p> </li> </ul>"},{"location":"reference/msm/#bespokefit_smee.msm.apply_msm","title":"apply_msm","text":"<pre><code>apply_msm(\n    mol: Molecule,\n    off_ff: ForceField,\n    tensor_top: TensorTopology,\n    tensor_ff: TensorForceField,\n    device: device,\n    settings: MSMSettings,\n) -&gt; TensorForceField\n</code></pre> <p>Generate modified Seminario parameters for the bond and angle terms in the force-field and apply these to the tensor ff. see doi: 10.1021/acs.jctc.7b00785</p> Source code in <code>bespokefit_smee/msm.py</code> <pre><code>def apply_msm(\n    mol: openff.toolkit.Molecule,\n    off_ff: openff.toolkit.ForceField,\n    tensor_top: smee.TensorTopology,\n    tensor_ff: smee.TensorForceField,\n    device: torch.device,\n    settings: MSMSettings,\n) -&gt; smee.TensorForceField:\n    \"\"\"Generate modified Seminario parameters for the bond and angle terms in the\n    force-field and apply these to the tensor ff. see doi: 10.1021/acs.jctc.7b00785\n    \"\"\"\n    from openmm import LangevinMiddleIntegrator\n    from openmm.app.simulation import Simulation\n\n    from .writers import get_potential_comparison\n\n    #   set up an MD sim with the ML potential\n    molecule = copy.deepcopy(mol)\n    molecule.generate_conformers(n_conformers=1)\n    interchange = openff.interchange.Interchange.from_smirnoff(\n        off_ff, openff.toolkit.Topology.from_molecules(molecule)\n    )\n    integrator = LangevinMiddleIntegrator(0 * _OMM_KELVIN, 1 / _OMM_PS, 0.01 * _OMM_PS)\n    potential = mlp.get_mlp(settings.ml_potential)\n    with open(\"/dev/null\", \"w\") as f:\n        with redirect_stdout(f):\n            system = potential.createSystem(\n                interchange.to_openmm_topology(),\n                charge=mol.total_charge.m_as(off_unit.e),\n                device=device,\n            )\n    simulation = Simulation(interchange.topology, system, integrator)\n    #   calculate the ground-state geometry and energy\n    interchange.positions = molecule.conformers[0]\n    simulation.context.setPositions(interchange.positions.to_openmm())\n    simulation.minimizeEnergy(maxIterations=0, tolerance=settings.tolerance)\n    position = simulation.context.getState(getPositions=True).getPositions(asNumpy=True)\n    crd0 = position.value_in_unit(_OMM_NM).reshape(3 * molecule.n_atoms)\n    #   extract bond info from the smee tensor\n    bonds_obj = cast(\n        smee.ValenceParameterMap, copy.deepcopy(tensor_top.parameters[\"Bonds\"])\n    )\n    n_bonds = len(bonds_obj.assignment_matrix.indices()[0].detach().flatten().tolist())\n    n_bond_types = (\n        max(bonds_obj.assignment_matrix.indices()[-1].detach().flatten().tolist()) + 1\n    )\n    bond_types = [\n        [\n            i\n            for i, x in enumerate(bonds_obj.assignment_matrix.indices()[-1].tolist())\n            if x == j\n        ]\n        for j in range(n_bond_types)\n    ]\n    bond_indxs = bonds_obj.particle_idxs.tolist()\n    #   extract angle info from the smee tensor\n    angles_obj = cast(\n        smee.ValenceParameterMap, copy.deepcopy(tensor_top.parameters[\"Angles\"])\n    )\n    n_angles = len(\n        angles_obj.assignment_matrix.indices()[0].detach().flatten().tolist()\n    )\n    n_angle_types = (\n        max(angles_obj.assignment_matrix.indices()[-1].detach().flatten().tolist()) + 1\n    )\n    angle_types = [\n        [\n            i\n            for i, x in enumerate(angles_obj.assignment_matrix.indices()[-1].tolist())\n            if x == j\n        ]\n        for j in range(n_angle_types)\n    ]\n    angle_indxs = angles_obj.particle_idxs.tolist()\n    #   calculate hessian elements with finite difference, ignoring the diagonal and all below\n    hessian = np.zeros((3 * molecule.n_atoms, 3 * molecule.n_atoms))\n    for i in tqdm(\n        range(n_bonds), leave=False, colour=\"green\", desc=\"Generating Hessian Fragments\"\n    ):\n        i1, i2 = bond_indxs[i][0] * 3, bond_indxs[i][1] * 3\n        for j1 in range(i1, i1 + 3):\n            crd = crd0\n            crd[j1] += settings.finite_step\n            simulation.context.setPositions(\n                crd.reshape(molecule.n_atoms, 3)\n            )  # coords +\n            f1 = (\n                simulation.context.getState(getForces=True)\n                .getForces(asNumpy=True)\n                .value_in_unit(_OMM_KCAL_PER_MOL_ANGS)\n            )\n            dEp = -f1[i2 // 3]\n            crd[j1] -= 2 * settings.finite_step\n            simulation.context.setPositions(\n                crd.reshape(molecule.n_atoms, 3)\n            )  # coords -\n            f1 = (\n                simulation.context.getState(getForces=True)\n                .getForces(asNumpy=True)\n                .value_in_unit(_OMM_KCAL_PER_MOL_ANGS)\n            )\n            dEm = -f1[i2 // 3]\n            hessian[j1, range(i2, i2 + 3)] = (dEp - dEm) / (2 * settings.finite_step)\n    #   calculate mod-seminario force constants along the bonds and group by bond-type, as given in the smee tensors\n    bond_k, bond_l = [], []\n    for j in range(n_bond_types):\n        k_sum, l_sum = 0.0, 0.0\n        for i in bond_types[j]:\n            iA, iB = bond_indxs[i][0], bond_indxs[i][1]\n            jA, jB = iA * 3, iB * 3\n            b = (\n                position.value_in_unit(_OMM_ANGS)[iA]\n                - position.value_in_unit(_OMM_ANGS)[iB]\n            )\n            norm_b = np.linalg.norm(b)\n            k_sum += modSem_projection(-hessian[jA : jA + 3, jB : jB + 3], b / norm_b)\n            l_sum += float(norm_b)\n        bond_k.append(k_sum * settings.vib_scaling**2 * 0.1 / len(bond_types[j]))\n        bond_l.append(l_sum / len(bond_types[j]))\n    #   calculate mod-seminario force constants along around the angles and group by angle-type, as given in the smee tensors\n    angle_k, angle_t = [], []\n    for j in range(n_angle_types):\n        k_sum, t_sum = 0.0, 0.0\n        for i in angle_types[j]:\n            iA, iB, iC = angle_indxs[i][0], angle_indxs[i][1], angle_indxs[i][2]\n            jA, jB, jC = iA * 3, iB * 3, iC * 3\n            bAB = (\n                position.value_in_unit(_OMM_ANGS)[iA]\n                - position.value_in_unit(_OMM_ANGS)[iB]\n            )\n            bCB = (\n                position.value_in_unit(_OMM_ANGS)[iC]\n                - position.value_in_unit(_OMM_ANGS)[iB]\n            )\n            if iA &gt; iB:\n                HAB = -hessian[jB : jB + 3, jA : jA + 3]\n            else:\n                HAB = -hessian[jA : jA + 3, jB : jB + 3]\n            if iC &gt; iB:\n                HCB = -hessian[jB : jB + 3, jC : jC + 3]\n            else:\n                HCB = -hessian[jC : jC + 3, jB : jB + 3]\n            lAB, lCB = np.linalg.norm(bAB), np.linalg.norm(bCB)\n            uAB, uCB = bAB / lAB, bCB / lCB\n            uN = unit_normal_vector(uAB, uCB)\n            uPA, uPC = unit_normal_vector(uN, uAB), unit_normal_vector(uCB, uN)\n            kPA, kPC = modSem_projection(HAB, uPA), modSem_projection(HCB, uPC)\n            fixA, fixC = 0.0, 0.0\n            NfA, NfC = 0.0, 0.0\n            for jj in range(n_angles):\n                iiA, iiB, iiC = (\n                    angle_indxs[jj][0],\n                    angle_indxs[jj][1],\n                    angle_indxs[jj][2],\n                )\n                if iiB == iB &amp; jj != i:\n                    if iiA == iA:\n                        bCBp = (\n                            position.value_in_unit(_OMM_ANGS)[iiC]\n                            - position.value_in_unit(_OMM_ANGS)[iiB]\n                        )\n                        uPAp = unit_normal_vector(\n                            unit_normal_vector(uAB, bCBp / np.linalg.norm(bCBp)), uAB\n                        )\n                        fixA += np.dot(uPA, uPAp) ** 2\n                        NfA += 1\n                    elif iiC == iC:\n                        bABp = (\n                            position.value_in_unit(_OMM_ANGS)[iiA]\n                            - position.value_in_unit(_OMM_ANGS)[iiB]\n                        )\n                        uPCp = unit_normal_vector(\n                            unit_normal_vector(uCB, bABp / np.linalg.norm(bABp)), uCB\n                        )\n                        fixC += np.dot(uPC, uPCp) ** 2\n                        NfC += 1\n            if NfA &gt; 0:\n                fixA = fixA / NfA\n            if NfC &gt; 0:\n                fixC = fixC / NfC\n            k_sum += float(\n                1 / (((1 + fixA) / (lAB**2 * kPA)) + ((1 + fixC) / (lCB**2 * kPC)))\n            )\n            t_sum += np.arccos(np.dot(uAB, uCB))\n        angle_k.append(k_sum * settings.vib_scaling**2 * 0.1 / len(angle_types[j]))\n        angle_t.append(t_sum / len(angle_types[j]))\n    #   put the new constants into the force-field object and report!\n    tensor_ff_out = copy.deepcopy(tensor_ff)\n    tensor_ff_out.potentials_by_type[\"Bonds\"].parameters = torch.tensor(\n        [[bond_k[j], bond_l[j]] for j in range(n_bond_types)]\n    )\n    tensor_ff_out.potentials_by_type[\"Angles\"].parameters = torch.tensor(\n        [[angle_k[j], angle_t[j]] for j in range(n_angle_types)]\n    )\n    bond_potential_comparison = get_potential_comparison(\n        tensor_ff.potentials_by_type[\"Bonds\"],\n        tensor_ff_out.potentials_by_type[\"Bonds\"],\n    )\n    angle_potential_comparison = get_potential_comparison(\n        tensor_ff.potentials_by_type[\"Angles\"],\n        tensor_ff_out.potentials_by_type[\"Angles\"],\n    )\n\n    logger.info(\n        \"Modified Seminario Summary:\"\n        f\"{bond_potential_comparison}\"\n        f\"{angle_potential_comparison}\"\n    )\n\n    return tensor_ff_out\n</code></pre>"},{"location":"reference/msm/#bespokefit_smee.msm.unit_normal_vector","title":"unit_normal_vector","text":"<pre><code>unit_normal_vector(\n    u1: NDArray[float64], u2: NDArray[float64]\n) -&gt; NDArray[float64]\n</code></pre> <p>Return a unit vector perpendicular to the two input vectors</p> Source code in <code>bespokefit_smee/msm.py</code> <pre><code>def unit_normal_vector(\n    u1: npt.NDArray[np.float64], u2: npt.NDArray[np.float64]\n) -&gt; npt.NDArray[np.float64]:\n    \"\"\"Return a unit vector perpendicular to the two input vectors\"\"\"\n    cross = np.cross(u1, u2)\n    return cross / np.linalg.norm(cross)\n</code></pre>"},{"location":"reference/msm/#bespokefit_smee.msm.modSem_projection","title":"modSem_projection","text":"<pre><code>modSem_projection(\n    parhess: NDArray[float64], unit_vector: NDArray[float64]\n) -&gt; float\n</code></pre> <p>Return a spring constant projected out of a partial hessian onto a unit vector</p> Source code in <code>bespokefit_smee/msm.py</code> <pre><code>def modSem_projection(\n    parhess: npt.NDArray[np.float64], unit_vector: npt.NDArray[np.float64]\n) -&gt; float:\n    \"\"\"Return a spring constant projected out of a partial hessian onto a unit vector\"\"\"\n    vals, vecs = np.linalg.eig(parhess)\n    kab1 = sum(abs(np.dot(unit_vector, vecs[:, i])) * vals[i] for i in range(3)).real\n    kba1 = sum(\n        abs(np.dot(unit_vector[::-1], vecs[:, i])) * vals[i] for i in range(3)\n    ).real\n    vals, vecs = np.linalg.eig(parhess.transpose())\n    kab2 = sum(abs(np.dot(unit_vector, vecs[:, i])) * vals[i] for i in range(3)).real\n    kba2 = sum(\n        abs(np.dot(unit_vector[::-1], vecs[:, i])) * vals[i] for i in range(3)\n    ).real\n    return float(0.25 * (kab1 + kba1 + kab2 + kba2))\n</code></pre>"},{"location":"reference/outputs/","title":"outputs","text":""},{"location":"reference/outputs/#bespokefit_smee.outputs","title":"outputs","text":"<p>Functionality for handling the outputs of a workflow.</p> <p>Classes:</p> <ul> <li> <code>OutputType</code>           \u2013            <p>An enumeration of the different types of outputs produced by bespoke fitting functions</p> </li> <li> <code>WorkflowPathManager</code>           \u2013            <p>Manages paths for workflow outputs based on WorkflowSettings.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>delete_path</code>             \u2013              <p>Delete an output file or directory if it exists. Deletes the entire contents of</p> </li> </ul>"},{"location":"reference/outputs/#bespokefit_smee.outputs.OutputType","title":"OutputType","text":"<p>               Bases: <code>Enum</code></p> <p>An enumeration of the different types of outputs produced by bespoke fitting functions</p>"},{"location":"reference/outputs/#bespokefit_smee.outputs.WorkflowPathManager","title":"WorkflowPathManager  <code>dataclass</code>","text":"<pre><code>WorkflowPathManager(\n    output_dir: Path,\n    n_iterations: int = 1,\n    training_settings: TrainingSettings | None = None,\n    training_sampling_settings: (\n        SamplingSettings | None\n    ) = None,\n    testing_sampling_settings: (\n        SamplingSettings | None\n    ) = None,\n)\n</code></pre> <p>Manages paths for workflow outputs based on WorkflowSettings.</p> <p>Methods:</p> <ul> <li> <code>get_stage_path</code>             \u2013              <p>Get the directory path for a workflow stage.</p> </li> <li> <code>mk_stage_dir</code>             \u2013              <p>Create the directory for a workflow stage.</p> </li> <li> <code>get_output_path</code>             \u2013              <p>Get the path for an output type in a stage.</p> </li> <li> <code>get_all_output_paths</code>             \u2013              <p>Get all expected output paths organized by stage.</p> </li> <li> <code>get_all_output_paths_by_output_type</code>             \u2013              <p>Get all expected output paths organized by output type.</p> </li> <li> <code>clean</code>             \u2013              <p>Remove all output files and empty stage directories.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>outputs_by_stage</code>               (<code>dict[OutputStage, set[OutputType]]</code>)           \u2013            <p>Return a dictionary mapping each stage to expected output types.</p> </li> </ul>"},{"location":"reference/outputs/#bespokefit_smee.outputs.WorkflowPathManager.outputs_by_stage","title":"outputs_by_stage  <code>property</code>","text":"<pre><code>outputs_by_stage: dict[OutputStage, set[OutputType]]\n</code></pre> <p>Return a dictionary mapping each stage to expected output types.</p>"},{"location":"reference/outputs/#bespokefit_smee.outputs.WorkflowPathManager.get_stage_path","title":"get_stage_path","text":"<pre><code>get_stage_path(stage: OutputStage) -&gt; Path\n</code></pre> <p>Get the directory path for a workflow stage.</p> Source code in <code>bespokefit_smee/outputs.py</code> <pre><code>def get_stage_path(self, stage: OutputStage) -&gt; Path:\n    \"\"\"Get the directory path for a workflow stage.\"\"\"\n    if stage not in self.outputs_by_stage:\n        raise ValueError(f\"Unknown stage: {stage}\")\n    return self.output_dir / str(stage)\n</code></pre>"},{"location":"reference/outputs/#bespokefit_smee.outputs.WorkflowPathManager.mk_stage_dir","title":"mk_stage_dir","text":"<pre><code>mk_stage_dir(stage: OutputStage) -&gt; None\n</code></pre> <p>Create the directory for a workflow stage.</p> Source code in <code>bespokefit_smee/outputs.py</code> <pre><code>def mk_stage_dir(self, stage: OutputStage) -&gt; None:\n    \"\"\"Create the directory for a workflow stage.\"\"\"\n    path = self.get_stage_path(stage)\n    path.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/outputs/#bespokefit_smee.outputs.WorkflowPathManager.get_output_path","title":"get_output_path","text":"<pre><code>get_output_path(\n    stage: OutputStage, output_type: OutputType\n) -&gt; Path\n</code></pre> <p>Get the path for an output type in a stage.</p> Source code in <code>bespokefit_smee/outputs.py</code> <pre><code>def get_output_path(self, stage: OutputStage, output_type: OutputType) -&gt; Path:\n    \"\"\"Get the path for an output type in a stage.\"\"\"\n    if stage not in self.outputs_by_stage:\n        raise ValueError(f\"Unknown stage: {stage}\")\n    if output_type not in self.outputs_by_stage.get(stage, set()):\n        raise ValueError(f\"Output type {output_type} not expected in stage {stage}\")\n\n    return self.get_stage_path(stage) / output_type.value\n</code></pre>"},{"location":"reference/outputs/#bespokefit_smee.outputs.WorkflowPathManager.get_all_output_paths","title":"get_all_output_paths","text":"<pre><code>get_all_output_paths(\n    only_if_exists: bool = True,\n) -&gt; dict[OutputStage, dict[OutputType, Path]]\n</code></pre> <p>Get all expected output paths organized by stage.</p> Source code in <code>bespokefit_smee/outputs.py</code> <pre><code>def get_all_output_paths(\n    self, only_if_exists: bool = True\n) -&gt; dict[OutputStage, dict[OutputType, Path]]:\n    \"\"\"Get all expected output paths organized by stage.\"\"\"\n    all_paths = {}\n\n    for stage in self.outputs_by_stage:\n        paths_for_stage = {}\n        for output_type in self.outputs_by_stage.get(stage, set()):\n            path = self.get_output_path(stage, output_type)\n            if not only_if_exists or path.exists():\n                paths_for_stage[output_type] = path\n\n        if paths_for_stage:\n            all_paths[stage] = paths_for_stage\n\n    return all_paths\n</code></pre>"},{"location":"reference/outputs/#bespokefit_smee.outputs.WorkflowPathManager.get_all_output_paths_by_output_type","title":"get_all_output_paths_by_output_type","text":"<pre><code>get_all_output_paths_by_output_type(\n    only_if_exists: bool = True,\n) -&gt; dict[OutputType, list[Path]]\n</code></pre> <p>Get all expected output paths organized by output type.</p> Source code in <code>bespokefit_smee/outputs.py</code> <pre><code>def get_all_output_paths_by_output_type(\n    self, only_if_exists: bool = True\n) -&gt; dict[OutputType, list[Path]]:\n    \"\"\"Get all expected output paths organized by output type.\"\"\"\n    all_paths = self.get_all_output_paths(only_if_exists=only_if_exists)\n    paths_by_output_type: dict[OutputType, list[Path]] = defaultdict(list)\n\n    for _, paths in all_paths.items():\n        for output_type, path in paths.items():\n            paths_by_output_type[output_type].append(path)\n\n    return paths_by_output_type\n</code></pre>"},{"location":"reference/outputs/#bespokefit_smee.outputs.WorkflowPathManager.clean","title":"clean","text":"<pre><code>clean() -&gt; None\n</code></pre> <p>Remove all output files and empty stage directories.</p> Source code in <code>bespokefit_smee/outputs.py</code> <pre><code>def clean(self) -&gt; None:\n    \"\"\"Remove all output files and empty stage directories.\"\"\"\n\n    # Delete all output files\n    all_paths = self.get_all_output_paths(only_if_exists=True)\n\n    for paths in all_paths.values():\n        for output_type, path in paths.items():\n            if output_type == OutputType.WORKFLOW_SETTINGS:\n                continue  # Don't delete workflow settings\n            delete_path(path, recursive=True)\n\n    # Remove empty stage directories\n    for stage in self.outputs_by_stage.keys():\n        if stage.kind == StageKind.BASE:\n            continue\n        delete_path(self.get_stage_path(stage), recursive=False)\n</code></pre>"},{"location":"reference/outputs/#bespokefit_smee.outputs.delete_path","title":"delete_path","text":"<pre><code>delete_path(path: Path, recursive: bool = False) -&gt; None\n</code></pre> <p>Delete an output file or directory if it exists. Deletes the entire contents of a directory.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>Path</code>)           \u2013            <p>The path to delete.</p> </li> <li> <code>recursive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to delete directories recursively, by default False. If False, only empty directories will be deleted.</p> </li> </ul> Source code in <code>bespokefit_smee/outputs.py</code> <pre><code>def delete_path(path: Path, recursive: bool = False) -&gt; None:\n    \"\"\"Delete an output file or directory if it exists. Deletes the entire contents of\n    a directory.\n\n    Parameters\n    ----------\n    path : Path\n        The path to delete.\n\n    recursive : bool, optional\n        Whether to delete directories recursively, by default False. If False, only\n        empty directories will be deleted.\n    \"\"\"\n    if not path.exists():\n        return\n\n    if path.is_dir():\n        if recursive:\n            for child in path.iterdir():\n                delete_path(child, recursive=True)\n        path.rmdir()  # Will only remove if empty\n    else:\n        path.unlink()\n</code></pre>"},{"location":"reference/parameterise/","title":"parameterise","text":""},{"location":"reference/parameterise/#bespokefit_smee.parameterise","title":"parameterise","text":"<p>Functionality for generating the initial parameterisation.</p> <p>Functions:</p> <ul> <li> <code>convert_to_smirnoff</code>             \u2013              <p>Convert a tensor force field that contains bespoke valence parameters to</p> </li> <li> <code>parameterise</code>             \u2013              <p>Prepare a Trainable object that contains a force field with</p> </li> <li> <code>linearize_harmonics</code>             \u2013              <p>Linearize the harmonic potential parameters in the forcefield for more robust optimization</p> </li> <li> <code>linearize_propertorsions</code>             \u2013              <p>Linearize the proper torsion parameters in the forcefield for more robust optimization</p> </li> <li> <code>linearize_impropertorsions</code>             \u2013              <p>Linearize the improper torsion parameters in the forcefield for more robust optimization</p> </li> </ul>"},{"location":"reference/parameterise/#bespokefit_smee.parameterise.convert_to_smirnoff","title":"convert_to_smirnoff","text":"<pre><code>convert_to_smirnoff(\n    ff: TensorForceField, base: ForceField | None = None\n) -&gt; ForceField\n</code></pre> <p>Convert a tensor force field that contains bespoke valence parameters to SMIRNOFF format. Args:     ff: The force field containing the bespoke valence terms.     base: The (optional) original SMIRNOFF force field to add the bespoke         parameters to. If no specified, a force field containing only the bespoke         parameters will be returned. Returns:     A SMIRNOFF force field containing the valence terms of the input force field.</p> Source code in <code>bespokefit_smee/parameterise.py</code> <pre><code>def convert_to_smirnoff(\n    ff: smee.TensorForceField, base: openff.toolkit.ForceField | None = None\n) -&gt; openff.toolkit.ForceField:\n    \"\"\"Convert a tensor force field that *contains bespoke valence parameters* to\n    SMIRNOFF format.\n    Args:\n        ff: The force field containing the bespoke valence terms.\n        base: The (optional) original SMIRNOFF force field to add the bespoke\n            parameters to. If no specified, a force field containing only the bespoke\n            parameters will be returned.\n    Returns:\n        A SMIRNOFF force field containing the valence terms of the input force field.\n    \"\"\"\n    ff_smirnoff = openff.toolkit.ForceField() if base is None else copy.deepcopy(base)\n\n    for potential in ff.potentials:\n        if potential.type in {\"Bonds\", \"Angles\", \"ProperTorsions\", \"ImproperTorsions\"}:\n            assert potential.attribute_cols is None\n            parameters_by_smarts: dict[str, dict[int | None, torch.Tensor]] = (\n                collections.defaultdict(dict)\n            )\n            for parameter, parameter_key in zip(\n                potential.parameters, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(potential.type)\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict: dict[str, str | Quantity] = {\n                    \"smirks\": smarts,\n                    \"id\": parameter_id,\n                }\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * potential.parameter_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(potential.parameter_cols)\n                    }\n                )\n                if current_param := handler.get_parameter(\n                    {\"smirks\": parameter_dict[\"smirks\"]}\n                ):\n                    logger.warning(\n                        f\"Parameter with smirks {parameter_dict['smirks']} already exists in the force field.\"\n                        f\"Current parameter: {current_param}. New parameter: {parameter_dict}. Skipping addition of new parameter.\"\n                    )\n                    continue\n                handler.add_parameter(parameter_dict)\n        elif potential.type == \"LinearBonds\":\n            assert potential.attribute_cols is None\n            parameters_by_smarts = collections.defaultdict(dict)\n            new_params = []\n            for param in potential.parameters:\n                k1 = param[0].item()\n                k2 = param[1].item()\n                b1 = param[2].item()\n                b2 = param[3].item()\n                k = k1 + k2\n                b = (k1 * b1 + k2 * b2) / k\n                dt = param.dtype\n                new_params.append([k, b])\n            reconstructed_param = torch.tensor(new_params, dtype=dt)\n            reconstructed_units = (_KCAL_PER_MOL_ANGSQ, _ANGSTROM)\n            reconstructed_cols = (\"k\", \"length\")\n            for parameter, parameter_key in zip(\n                reconstructed_param, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(\"Bonds\")\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict = {\"smirks\": smarts, \"id\": parameter_id}\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * reconstructed_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(reconstructed_cols)\n                    }\n                )\n                handler.add_parameter(parameter_dict)\n        elif potential.type == \"LinearAngles\":\n            assert potential.attribute_cols is None\n            parameters_by_smarts = collections.defaultdict(dict)\n            new_params = []\n            for param in potential.parameters:\n                k1 = param[0].item()\n                k2 = param[1].item()\n                a1 = param[2].item()\n                a2 = param[3].item()\n                k = k1 + k2\n                # Set k and angle to 0 if very close\n                a = (k1 * a1 + k2 * a2) / k\n                # Ensure that the angle is in the range [0, pi)\n                a = _reflect_angle(a)\n                dt = param.dtype\n                new_params.append([k, a])\n            reconstructed_param = torch.tensor(new_params, dtype=dt)\n            reconstructed_units = (_KCAL_PER_MOL_RADSQ, _RADIANS)\n            reconstructed_cols = (\"k\", \"angle\")\n            for parameter, parameter_key in zip(\n                reconstructed_param, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(\"Angles\")\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict = {\"smirks\": smarts, \"id\": parameter_id}\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * reconstructed_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(reconstructed_cols)\n                    }\n                )\n                handler.add_parameter(parameter_dict)\n        elif potential.type == \"LinearProperTorsions\":\n            assert potential.attribute_cols is None\n            parameters_by_smarts = collections.defaultdict(dict)\n            new_params = []\n            for param in potential.parameters:\n                k1 = param[0].item()\n                k2 = param[1].item()\n                periodicity = param[2].item()\n                # Params 3 and 4 are phase1 and phase2\n                idivf = param[5].item()\n                k = k1 + k2\n                if k == 0.0:\n                    phase = 0.0\n                else:\n                    phase = math.acos((k1 - k2) / k)\n                dt = param.dtype\n                new_params.append([k, periodicity, phase, idivf])\n            reconstructed_param = torch.tensor(new_params, dtype=dt)\n            reconstructed_torsion_units = (\n                _KCAL_PER_MOL,\n                _UNITLESS,\n                _RADIANS,\n                _UNITLESS,\n            )\n            reconstructed_torsion_cols = (\"k\", \"periodicity\", \"phase\", \"idivf\")\n            for parameter, parameter_key in zip(\n                reconstructed_param, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(\"ProperTorsions\")\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict = {\"smirks\": smarts, \"id\": parameter_id}\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * reconstructed_torsion_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(reconstructed_torsion_cols)\n                    }\n                )\n                handler.add_parameter(parameter_dict)\n        elif potential.type == \"LinearImproperTorsions\":\n            assert potential.attribute_cols is None\n            parameters_by_smarts = collections.defaultdict(dict)\n            new_params = []\n            for param in potential.parameters:\n                k1 = param[0].item()\n                k2 = param[1].item()\n                periodicity = param[2].item()\n                # Params 3 and 4 are phase1 and phase2\n                idivf = param[5].item()\n                k = k1 + k2\n                if k == 0.0:\n                    phase = 0.0\n                else:\n                    phase = math.acos((k1 - k2) / k)\n                #                    phase = math.acos((k1 * math.cos(phase1) + k2 * math.cos(phase2))/k)\n                dt = param.dtype\n                new_params.append([k, periodicity, phase, idivf])\n            reconstructed_param = torch.tensor(new_params, dtype=dt)\n            reconstructed_torsion_units = (\n                _KCAL_PER_MOL,\n                _UNITLESS,\n                _RADIANS,\n                _UNITLESS,\n            )\n            reconstructed_torsion_cols = (\"k\", \"periodicity\", \"phase\", \"idivf\")\n            for parameter, parameter_key in zip(\n                reconstructed_param, potential.parameter_keys, strict=True\n            ):\n                assert parameter_key.mult not in parameters_by_smarts[parameter_key.id]\n                parameters_by_smarts[parameter_key.id][parameter_key.mult] = parameter\n            handler = ff_smirnoff.get_parameter_handler(\"ImproperTorsions\")\n            for smarts, parameters_by_mult in parameters_by_smarts.items():\n                mults = {*parameters_by_mult}\n                if None in mults and len(mults) &gt; 1:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                if None not in mults and mults != {*range(len(mults))}:\n                    raise NotImplementedError(\"unexpected parameters found\")\n                counter = len(handler.parameters) + 1\n                parameter_id = f\"{potential.type[0].lower()}-bespoke-{counter}\"\n                parameter_dict = {\"smirks\": smarts, \"id\": parameter_id}\n                parameter_dict.update(\n                    {\n                        (col if mult is None else f\"{col}{mult + 1}\"): float(\n                            parameter[col_idx]\n                        )\n                        * reconstructed_torsion_units[col_idx]\n                        for mult, parameter in parameters_by_mult.items()\n                        for col_idx, col in enumerate(reconstructed_torsion_cols)\n                    }\n                )\n                handler.add_parameter(parameter_dict)\n\n    return ff_smirnoff\n</code></pre>"},{"location":"reference/parameterise/#bespokefit_smee.parameterise.parameterise","title":"parameterise","text":"<pre><code>parameterise(\n    settings: ParameterisationSettings,\n    device: TorchDevice = \"cuda\",\n) -&gt; tuple[\n    Molecule,\n    ForceField,\n    TensorTopology,\n    TensorForceField,\n    Trainable,\n]\n</code></pre> <p>Prepare a Trainable object that contains a force field with unique parameters for each topologically symmetric term of a molecule.</p> <p>Parameters:</p> <ul> <li> <code>settings</code>               (<code>ParameterisationSettings</code>)           \u2013            <p>The settings for the parameterisation.</p> </li> <li> <code>device</code>               (<code>TorchDevice</code>, default:                   <code>'cuda'</code> )           \u2013            <p>The device to use for the force field and topology.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>mol</code> (              <code>Molecule</code> )          \u2013            <p>The molecule that has been parameterised.</p> </li> <li> <code>off_ff</code> (              <code>ForceField</code> )          \u2013            <p>The original force field, used as a base for the bespoke force field.</p> </li> <li> <code>tensor_top</code> (              <code>TensorTopology</code> )          \u2013            <p>The topology of the molecule.</p> </li> <li> <code>tensor_ff</code> (              <code>TensorForceField</code> )          \u2013            <p>The force field with unique parameters for each topologically symmetric term.</p> </li> <li> <code>trainable</code> (              <code>Trainable</code> )          \u2013            <p>The trainable object that contains the force field and parameter configuration.</p> </li> </ul> Source code in <code>bespokefit_smee/parameterise.py</code> <pre><code>def parameterise(\n    settings: ParameterisationSettings,\n    device: TorchDevice = \"cuda\",\n) -&gt; tuple[\n    openff.toolkit.Molecule,\n    openff.toolkit.ForceField,\n    smee.TensorTopology,\n    smee.TensorForceField,\n    Trainable,\n]:\n    \"\"\"Prepare a Trainable object that contains a force field with\n    unique parameters for each topologically symmetric term of a molecule.\n\n    Parameters\n    ----------\n    settings: ParameterisationSettings\n        The settings for the parameterisation.\n\n    device: TorchDevice, default \"cuda\"\n        The device to use for the force field and topology.\n\n    Returns\n    -------\n    mol: openff.toolkit.Molecule\n        The molecule that has been parameterised.\n    off_ff: openff.toolkit.ForceField\n        The original force field, used as a base for the bespoke force field.\n    tensor_top: smee.TensorTopology\n        The topology of the molecule.\n    tensor_ff: smee.TensorForceField\n        The force field with unique parameters for each topologically symmetric term.\n    trainable: descent.train.Trainable\n        The trainable object that contains the force field and parameter configuration.\n    \"\"\"\n    mol = openff.toolkit.Molecule.from_smiles(\n        settings.smiles, allow_undefined_stereo=True, hydrogens_are_explicit=False\n    )\n    off_ff = openff.toolkit.ForceField(settings.initial_force_field)\n\n    if \"[#1:1]-[*:2]\" in off_ff[\"Constraints\"].parameters:\n        logger.warning(\n            \"The force field contains a constraint for [#1:1]-[*:2] which is not supported. \"\n            \"Removing this constraint.\"\n        )\n        del off_ff[\"Constraints\"].parameters[\"[#1:1]-[*:2]\"]\n\n    if settings.expand_torsions:\n        off_ff = _expand_torsions(off_ff, settings.excluded_smirks)\n\n    force_field, [topology] = smee.converters.convert_interchange(\n        openff.interchange.Interchange.from_smirnoff(off_ff, mol.to_topology())\n    )\n\n    # Move the force field and topology to the requested device\n    force_field = force_field.to(device)\n    topology = topology.to(device)\n\n    symmetries = list(Chem.CanonicalRankAtoms(mol.to_rdkit(), breakTies=False))\n    if topology.n_v_sites != 0:\n        raise NotImplementedError(\"virtual sites are not supported yet.\")\n\n    excluded_keys = collections.defaultdict(list)\n    for potential in force_field.potentials:\n        parameter_map = topology.parameters[potential.type]\n        if isinstance(parameter_map, smee.NonbondedParameterMap):\n            continue\n        # TODO: Check Tom's comment below\n        excluded_keys[potential.type] = _prepare_potential(\n            mol, symmetries, potential, parameter_map, settings.excluded_smirks\n        )  ### ??? is it re-ordering the atoms and bonds?\n\n    if settings.msm_settings is not None:\n        raise NotImplementedError(\"MSM is not supported yet.\")\n\n        force_field = apply_msm(\n            mol=mol,\n            off_ff=off_ff,\n            tensor_top=topology,\n            tensor_ff=force_field,\n            device=device,\n            settings=settings.msm_settings,\n        )\n\n    # Parameter scales obtained from trained force field - but only for linearised bonds and\n    # angles and unlinearised harmonics.\n    if settings.linear_harmonics:\n        topology.parameters[\"LinearBonds\"] = copy.deepcopy(topology.parameters[\"Bonds\"])\n        topology.parameters[\"LinearAngles\"] = copy.deepcopy(\n            topology.parameters[\"Angles\"]\n        )\n        force_field = linearize_harmonics(force_field, device)\n        parameter_list = {\n            \"LinearBonds\": ParameterConfig(\n                cols=[\"k1\", \"k2\"],\n                scales={\"k1\": 0.0024, \"k2\": 0.0024},\n                limits={\"k1\": (1e-8, None), \"k2\": (1e-8, None)},\n                exclude=excluded_keys[\"Bonds\"] if excluded_keys[\"Bonds\"] else None,\n            ),\n            \"LinearAngles\": ParameterConfig(\n                cols=[\"k1\", \"k2\"],\n                scales={\"k1\": 0.0207, \"k2\": 0.0207},\n                limits={\"k1\": (1e-8, None), \"k2\": (1e-8, None)},\n                exclude=excluded_keys[\"Angles\"] if excluded_keys[\"Angles\"] else None,\n            ),\n        }\n    else:\n        parameter_list = {\n            \"Bonds\": ParameterConfig(\n                cols=[\"k\", \"length\"],\n                scales={\"k\": 1.0, \"length\": 1.0},\n                limits={\"k\": (0.0, None), \"length\": (0.0, None)},\n                exclude=excluded_keys[\"Bonds\"] if excluded_keys[\"Bonds\"] else None,\n            ),\n            \"Angles\": ParameterConfig(\n                cols=[\"k\", \"angle\"],\n                scales={\"k\": 1.0, \"angle\": 1.0},\n                limits={\"k\": (0.0, None), \"angle\": (0.0, math.pi)},\n                exclude=excluded_keys[\"Angles\"] if excluded_keys[\"Angles\"] else None,\n            ),\n        }\n    for potential in force_field.potentials:\n        if potential.type == \"ProperTorsions\":\n            if settings.linear_torsions:\n                topology.parameters[\"LinearProperTorsions\"] = copy.deepcopy(\n                    topology.parameters[\"ProperTorsions\"]\n                )\n                force_field = linearize_propertorsions(force_field, device)\n                parameter_list.update(\n                    {\n                        \"LinearProperTorsions\": ParameterConfig(\n                            cols=[\"k1\", \"k2\"],\n                            scales={\"k1\": 100.0, \"k2\": 100.0},\n                            limits={\"k1\": (0, None), \"k2\": (0, None)},\n                            exclude=(\n                                excluded_keys[\"ProperTorsions\"]\n                                if excluded_keys[\"ProperTorsions\"]\n                                else None\n                            ),\n                        )\n                    }\n                )\n            else:\n                parameter_list.update(\n                    {\n                        \"ProperTorsions\": ParameterConfig(\n                            cols=[\"k\"],\n                            scales={\n                                \"k\": 0.3252,\n                            },\n                            limits={\"k\": (None, None)},\n                            exclude=(\n                                excluded_keys[\"ProperTorsions\"]\n                                if excluded_keys[\"ProperTorsions\"]\n                                else None\n                            ),\n                        ),\n                    }\n                )\n        elif potential.type == \"ImproperTorsions\":\n            if settings.linear_torsions:\n                topology.parameters[\"LinearImproperTorsions\"] = copy.deepcopy(\n                    topology.parameters[\"ImproperTorsions\"]\n                )\n                force_field = linearize_impropertorsions(force_field, device)\n                parameter_list.update(\n                    {\n                        \"LinearImproperTorsions\": ParameterConfig(\n                            cols=[\"k1\", \"k2\"],\n                            scales={\"k1\": 100.0, \"k2\": 100.0},\n                            limits={\"k1\": (0, None), \"k2\": (0, None)},\n                            exclude=(\n                                excluded_keys[\"ImproperTorsions\"]\n                                if excluded_keys[\"ImproperTorsions\"]\n                                else None\n                            ),\n                        ),\n                    }\n                )\n            else:\n                parameter_list.update(\n                    {\n                        \"ImproperTorsions\": ParameterConfig(\n                            cols=[\"k\"],\n                            scales={\n                                \"k\": 0.1647,\n                            },\n                            limits={\"k\": (0, None)},\n                            exclude=(\n                                excluded_keys[\"ImproperTorsions\"]\n                                if excluded_keys[\"ImproperTorsions\"]\n                                else None\n                            ),\n                        ),\n                    }\n                )\n\n    return (\n        copy.deepcopy(mol),\n        copy.deepcopy(off_ff),\n        topology,\n        force_field,\n        Trainable(force_field, parameter_list, {}),\n    )\n</code></pre>"},{"location":"reference/parameterise/#bespokefit_smee.parameterise.linearize_harmonics","title":"linearize_harmonics","text":"<pre><code>linearize_harmonics(\n    ff: TensorForceField, device_type: str\n) -&gt; TensorForceField\n</code></pre> <p>Linearize the harmonic potential parameters in the forcefield for more robust optimization</p> Source code in <code>bespokefit_smee/parameterise.py</code> <pre><code>def linearize_harmonics(\n    ff: smee.TensorForceField, device_type: str\n) -&gt; smee.TensorForceField:\n    \"\"\"Linearize the harmonic potential parameters in the forcefield for more robust optimization\"\"\"\n    ff_copy = copy.deepcopy(ff)\n    ff_copy.potentials = []\n    for potential in ff.potentials:\n        if potential.type in {\"Bonds\"}:\n            new_potential = copy.deepcopy(potential)\n            new_potential.type = \"LinearBonds\"\n            new_potential.fn = \"(k1+k2)/2*(r-(k1*length1+k2*length2)/(k1+k2))**2\"\n            new_potential.parameter_cols = (\"k1\", \"k2\", \"b1\", \"b2\")\n            new_params = []\n            for param in potential.parameters:\n                k = param[0].item()\n                b = param[1].item()\n                dt = param.dtype\n                b1 = b * 0.5\n                b2 = b * 1.5\n                d = b2 - b1\n                k1 = k * (b2 - b) / d\n                k2 = k * (b - b1) / d\n                new_params.append([k1, k2, b1, b2])\n            new_potential.parameters = torch.tensor(\n                new_params, dtype=dt, requires_grad=False, device=device_type\n            )\n            new_potential.parameter_units = (\n                _KCAL_PER_MOL_ANGSQ,\n                _KCAL_PER_MOL_ANGSQ,\n                _ANGSTROM,\n                _ANGSTROM,\n            )\n            ff_copy.potentials.append(new_potential)\n        elif potential.type in {\"Angles\"}:\n            new_potential = copy.deepcopy(potential)\n            new_potential.type = \"LinearAngles\"\n            new_potential.fn = \"(k1+k2)/2*(r-(k1*angle1+k2*angle2)/(k1+k2))**2\"\n            new_potential.parameter_cols = (\"k1\", \"k2\", \"angle1\", \"angle2\")\n            new_params = []\n            for param in potential.parameters:\n                k = param[0].item()\n                a = param[1].item()\n                dt = param.dtype\n                # a1 = a * 0.9\n                # a2 = a * 1.1\n                a1 = 0.0\n                a2 = math.pi\n                d = a2 - a1\n                k1 = k * (a2 - a) / d\n                k2 = k * (a - a1) / d\n                new_params.append([k1, k2, a1, a2])\n            new_potential.parameters = torch.tensor(\n                new_params, dtype=dt, requires_grad=False, device=device_type\n            )\n            new_potential.parameter_units = (\n                _KCAL_PER_MOL_RADSQ,\n                _KCAL_PER_MOL_RADSQ,\n                _RADIANS,\n                _RADIANS,\n            )\n            ff_copy.potentials.append(new_potential)\n        else:\n            ff_copy.potentials.append(potential)\n    return ff_copy\n</code></pre>"},{"location":"reference/parameterise/#bespokefit_smee.parameterise.linearize_propertorsions","title":"linearize_propertorsions","text":"<pre><code>linearize_propertorsions(\n    ff: TensorForceField, device_type: str\n) -&gt; TensorForceField\n</code></pre> <p>Linearize the proper torsion parameters in the forcefield for more robust optimization</p> Source code in <code>bespokefit_smee/parameterise.py</code> <pre><code>def linearize_propertorsions(\n    ff: smee.TensorForceField, device_type: str\n) -&gt; smee.TensorForceField:\n    \"\"\"Linearize the proper torsion parameters in the forcefield for more robust optimization\"\"\"\n    ff_copy = copy.deepcopy(ff)\n    ff_copy.potentials = []\n    for potential in ff.potentials:\n        if potential.type in {\"ProperTorsions\"}:\n            new_potential = copy.deepcopy(potential)\n            new_potential.type = \"LinearProperTorsions\"\n            new_potential.fn = (\n                \"(k1+k2)*(1+cos(periodicity*theta-acos((k1-k2)/(k1+k2))))\"\n            )\n            new_potential.parameter_cols = (\n                \"k1\",\n                \"k2\",\n                \"periodicity\",\n                \"phase1\",\n                \"phase2\",\n                \"idivf\",\n            )\n            new_params = []\n            for param in potential.parameters:\n                k = param[0].item()\n                periodicity = param[1].item()\n                phase = param[2].item()\n                idivf = param[3].item()\n                dt = param.dtype\n                k1 = abs(k * 0.5 * (1 + math.cos(phase)))\n                k2 = abs(k * 0.5 * (1 - math.cos(phase)))\n                new_params.append([k1, k2, periodicity, 0.0, math.pi, idivf])\n            new_potential.parameters = torch.tensor(\n                new_params, dtype=dt, requires_grad=True, device=device_type\n            )\n            new_potential.parameter_units = (\n                _KCAL_PER_MOL,\n                _KCAL_PER_MOL,\n                _UNITLESS,\n                _RADIANS,\n                _RADIANS,\n                _UNITLESS,\n            )\n            ff_copy.potentials.append(new_potential)\n        else:\n            ff_copy.potentials.append(potential)\n    return ff_copy\n</code></pre>"},{"location":"reference/parameterise/#bespokefit_smee.parameterise.linearize_impropertorsions","title":"linearize_impropertorsions","text":"<pre><code>linearize_impropertorsions(\n    ff: TensorForceField, device_type: str\n) -&gt; TensorForceField\n</code></pre> <p>Linearize the improper torsion parameters in the forcefield for more robust optimization</p> Source code in <code>bespokefit_smee/parameterise.py</code> <pre><code>def linearize_impropertorsions(\n    ff: smee.TensorForceField, device_type: str\n) -&gt; smee.TensorForceField:\n    \"\"\"Linearize the improper torsion parameters in the forcefield for more robust optimization\"\"\"\n    ff_copy = copy.deepcopy(ff)\n    ff_copy.potentials = []\n    for potential in ff.potentials:\n        if potential.type in {\"ImproperTorsions\"}:\n            new_potential = copy.deepcopy(potential)\n            new_potential.type = \"LinearImproperTorsions\"\n            new_potential.fn = (\n                \"(k1+k2)*(1+cos(periodicity*theta-acos((k1-k2)/(k1+k2))))\"\n            )\n            new_potential.parameter_cols = (\n                \"k1\",\n                \"k2\",\n                \"periodicity\",\n                \"phase1\",\n                \"phase2\",\n                \"idivf\",\n            )\n            new_params = []\n            for param in potential.parameters:\n                k = param[0].item()\n                periodicity = param[1].item()\n                phase = param[2].item()\n                idivf = param[3].item()\n                dt = param.dtype\n                k1 = abs(k * 0.5 * (1 + math.cos(phase)))\n                k2 = abs(k * 0.5 * (1 - math.cos(phase)))\n                new_params.append([k1, k2, periodicity, 0.0, math.pi, idivf])\n            new_potential.parameters = torch.tensor(\n                new_params, dtype=dt, device=device_type\n            )\n            new_potential.parameter_units = (\n                _KCAL_PER_MOL,\n                _KCAL_PER_MOL,\n                _UNITLESS,\n                _RADIANS,\n                _RADIANS,\n                _UNITLESS,\n            )\n            ff_copy.potentials.append(new_potential)\n        else:\n            ff_copy.potentials.append(potential)\n    return ff_copy\n</code></pre>"},{"location":"reference/sample/","title":"sample","text":""},{"location":"reference/sample/#bespokefit_smee.sample","title":"sample","text":"<p>Functionality to obtain samples to fit the force field to.</p> <p>Classes:</p> <ul> <li> <code>SampleFnArgs</code>           \u2013            <p>Arguments for sampling functions.</p> </li> <li> <code>SampleFn</code>           \u2013            <p>A protocol for sampling functions.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>recalculate_energies_and_forces</code>             \u2013              <p>Recalculate energies and forces for a dataset using a given OpenMM simulation.</p> </li> <li> <code>sample_mmmd</code>             \u2013              <p>Generate a dataset of samples from MD with the given MM force field,</p> </li> <li> <code>sample_mlmd</code>             \u2013              <p>Generate a dataset of samples (with energies and forces) all</p> </li> <li> <code>sample_mmmd_metadynamics</code>             \u2013              <p>Generate a dataset of samples from MD with the given MM force field</p> </li> </ul>"},{"location":"reference/sample/#bespokefit_smee.sample.SampleFnArgs","title":"SampleFnArgs","text":"<p>               Bases: <code>TypedDict</code></p> <p>Arguments for sampling functions.</p>"},{"location":"reference/sample/#bespokefit_smee.sample.SampleFn","title":"SampleFn","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol for sampling functions.</p>"},{"location":"reference/sample/#bespokefit_smee.sample.recalculate_energies_and_forces","title":"recalculate_energies_and_forces","text":"<pre><code>recalculate_energies_and_forces(\n    dataset: Dataset, simulation: Simulation\n) -&gt; Dataset\n</code></pre> <p>Recalculate energies and forces for a dataset using a given OpenMM simulation.</p> Source code in <code>bespokefit_smee/sample.py</code> <pre><code>def recalculate_energies_and_forces(\n    dataset: datasets.Dataset, simulation: Simulation\n) -&gt; datasets.Dataset:\n    \"\"\"Recalculate energies and forces for a dataset using a given OpenMM simulation.\"\"\"\n\n    recalc_energies = []\n    recalc_forces = []\n\n    assert len(dataset) == 1, \"Dataset should contain exactly one entry.\"\n\n    entry = dataset[0]\n    n_conf = len(entry[\"energy\"])\n    coords = entry[\"coords\"].reshape(n_conf, -1, 3)\n\n    for i in tqdm(\n        range(n_conf),\n        leave=False,\n        colour=\"blue\",\n        desc=\"Recalculating energies and forces\",\n    ):\n        my_pos = Quantity(numpy.array(coords[i]), angstrom)\n        simulation.context.setPositions(my_pos)\n        state = simulation.context.getState(getEnergy=True, getForces=True)\n        recalc_energies.append(\n            state.getPotentialEnergy().value_in_unit(_OMM_KCAL_PER_MOL)\n        )\n        recalc_forces.append(\n            state.getForces(asNumpy=True).value_in_unit(_OMM_KCAL_PER_MOL_ANGS)\n        )\n\n    return descent.targets.energy.create_dataset(\n        [\n            {\n                \"smiles\": entry[\"smiles\"],\n                \"coords\": entry[\"coords\"],\n                \"energy\": torch.tensor(recalc_energies),\n                \"forces\": torch.tensor(recalc_forces),\n            }\n        ]\n    )\n</code></pre>"},{"location":"reference/sample/#bespokefit_smee.sample.sample_mmmd","title":"sample_mmmd","text":"<pre><code>sample_mmmd(\n    mol: Molecule,\n    off_ff: ForceField,\n    device: device,\n    settings: MMMDSamplingSettings,\n    output_paths: dict[OutputType, Path],\n) -&gt; Dataset\n</code></pre> <p>Generate a dataset of samples from MD with the given MM force field, and energies and forces of snapshots from the ML potential.</p> <p>Parameters:</p> <ul> <li> <code>mol</code>               (<code>Molecule</code>)           \u2013            <p>The molecule to sample.</p> </li> <li> <code>off_ff</code>               (<code>ForceField</code>)           \u2013            <p>The MM force field to use for sampling.</p> </li> <li> <code>device</code>               (<code>device</code>)           \u2013            <p>The device to use for any MD or ML calculations.</p> </li> <li> <code>settings</code>               (<code>_SamplingSettings</code>)           \u2013            <p>The sampling settings to use.</p> </li> <li> <code>output_paths</code>               (<code>dict[OutputType, Path]</code>)           \u2013            <p>A mapping of output types to filesystem paths.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>The generated dataset of samples with energies and forces.</p> </li> </ul> Source code in <code>bespokefit_smee/sample.py</code> <pre><code>@_register_sampling_fn(settings.MMMDSamplingSettings)\ndef sample_mmmd(\n    mol: openff.toolkit.Molecule,\n    off_ff: openff.toolkit.ForceField,\n    device: torch.device,\n    settings: settings.MMMDSamplingSettings,\n    output_paths: dict[OutputType, pathlib.Path],\n) -&gt; datasets.Dataset:\n    \"\"\"Generate a dataset of samples from MD with the given MM force field,\n    and energies and forces of snapshots from the ML potential.\n\n    Parameters\n    ----------\n    mol : openff.toolkit.Molecule\n        The molecule to sample.\n    off_ff : openff.toolkit.ForceField\n        The MM force field to use for sampling.\n    device : torch.device\n        The device to use for any MD or ML calculations.\n    settings : _SamplingSettings\n        The sampling settings to use.\n    output_paths: dict[OutputType, PathLike]\n        A mapping of output types to filesystem paths.\n\n    Returns\n    -------\n    datasets.Dataset\n        The generated dataset of samples with energies and forces.\n    \"\"\"\n    mol = _copy_mol_and_add_conformers(mol, settings.n_conformers)\n    interchange = openff.interchange.Interchange.from_smirnoff(\n        off_ff, openff.toolkit.Topology.from_molecules(mol)\n    )\n    system = interchange.to_openmm_system()\n    simulation = Simulation(\n        interchange.topology.to_openmm(),\n        system,\n        _get_integrator(settings.temperature, settings.timestep),\n    )\n\n    # First, generate the MD snapshots using the MM potential\n    mm_dataset = _run_md(\n        mol,\n        simulation,\n        simulation.step,\n        settings.equilibration_n_steps_per_conformer,\n        settings.production_n_snapshots_per_conformer,\n        settings.production_n_steps_per_snapshot_per_conformer,\n        str(output_paths.get(OutputType.PDB_TRAJECTORY, None)),\n    )\n\n    # Now, recalculate energies and forces using the ML potential\n    ml_system = _get_ml_omm_system(mol, settings.ml_potential)\n    ml_simulation = Simulation(\n        interchange.topology,\n        ml_system,\n        _get_integrator(settings.temperature, settings.timestep),\n    )\n    ml_dataset = recalculate_energies_and_forces(mm_dataset, ml_simulation)\n\n    return ml_dataset\n</code></pre>"},{"location":"reference/sample/#bespokefit_smee.sample.sample_mlmd","title":"sample_mlmd","text":"<pre><code>sample_mlmd(\n    mol: Molecule,\n    off_ff: ForceField,\n    device: device,\n    settings: MLMDSamplingSettings,\n    output_paths: dict[OutputType, Path],\n) -&gt; Dataset\n</code></pre> <p>Generate a dataset of samples (with energies and forces) all from MD with an ML potential.</p> <p>Parameters:</p> <ul> <li> <code>mol</code>               (<code>Molecule</code>)           \u2013            <p>The molecule to sample.</p> </li> <li> <code>off_ff</code>               (<code>ForceField</code>)           \u2013            <p>The MM force field. Kept for consistency with other sampling functions, but not used here.</p> </li> <li> <code>device</code>               (<code>device</code>)           \u2013            <p>The device to use for any MD or ML calculations.</p> </li> <li> <code>settings</code>               (<code>_SamplingSettings</code>)           \u2013            <p>The sampling settings to use.</p> </li> <li> <code>output_paths</code>               (<code>dict[OutputType, Path]</code>)           \u2013            <p>A mapping of output types to filesystem paths.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>The generated dataset of samples with energies and forces.</p> </li> </ul> Source code in <code>bespokefit_smee/sample.py</code> <pre><code>@_register_sampling_fn(settings.MLMDSamplingSettings)\ndef sample_mlmd(\n    mol: openff.toolkit.Molecule,\n    off_ff: openff.toolkit.ForceField,\n    device: torch.device,\n    settings: settings.MLMDSamplingSettings,\n    output_paths: dict[OutputType, pathlib.Path],\n) -&gt; datasets.Dataset:\n    \"\"\"Generate a dataset of samples (with energies and forces) all\n    from MD with an ML potential.\n\n    Parameters\n    ----------\n    mol : openff.toolkit.Molecule\n        The molecule to sample.\n    off_ff : openff.toolkit.ForceField\n        The MM force field. Kept for consistency with other sampling functions,\n        but not used here.\n    device : torch.device\n        The device to use for any MD or ML calculations.\n    settings : _SamplingSettings\n        The sampling settings to use.\n    output_paths: dict[OutputType, PathLike]\n        A mapping of output types to filesystem paths.\n\n    Returns\n    -------\n    datasets.Dataset\n        The generated dataset of samples with energies and forces.\n    \"\"\"\n    mol = _copy_mol_and_add_conformers(mol, settings.n_conformers)\n    ml_system = _get_ml_omm_system(mol, settings.ml_potential)\n    integrator = _get_integrator(settings.temperature, settings.timestep)\n    ml_simulation = Simulation(mol.to_topology().to_openmm(), ml_system, integrator)\n\n    # Generate the MD snapshots using the ML potential\n    ml_dataset = _run_md(\n        mol,\n        ml_simulation,\n        ml_simulation.step,\n        settings.equilibration_n_steps_per_conformer,\n        settings.production_n_snapshots_per_conformer,\n        settings.production_n_steps_per_snapshot_per_conformer,\n        str(output_paths.get(OutputType.PDB_TRAJECTORY, None)),\n    )\n\n    return ml_dataset\n</code></pre>"},{"location":"reference/sample/#bespokefit_smee.sample.sample_mmmd_metadynamics","title":"sample_mmmd_metadynamics","text":"<pre><code>sample_mmmd_metadynamics(\n    mol: Molecule,\n    off_ff: ForceField,\n    device: device,\n    settings: MMMDMetadynamicsSamplingSettings,\n    output_paths: dict[OutputType, Path],\n) -&gt; Dataset\n</code></pre> <p>Generate a dataset of samples from MD with the given MM force field with metadynamics samplings of the torsions. Each torsion is treated as an independent collective variable and biased independently. This function generates samples using the MM potential, and recalculates energies and forces of snapshots from the ML potential.</p> <p>Parameters:</p> <ul> <li> <code>mol</code>               (<code>Molecule</code>)           \u2013            <p>The molecule to sample.</p> </li> <li> <code>off_ff</code>               (<code>ForceField</code>)           \u2013            <p>The MM force field to use for sampling.</p> </li> <li> <code>device</code>               (<code>device</code>)           \u2013            <p>The device to use for any MD or ML calculations.</p> </li> <li> <code>settings</code>               (<code>MMMDMetadynamicsSamplingSettings</code>)           \u2013            <p>The sampling settings to use.</p> </li> <li> <code>output_paths</code>               (<code>dict[OutputType, Path]</code>)           \u2013            <p>A mapping of output types to filesystem paths.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>The generated dataset of samples with energies and forces.</p> </li> </ul> Source code in <code>bespokefit_smee/sample.py</code> <pre><code>@_register_sampling_fn(settings.MMMDMetadynamicsSamplingSettings)\ndef sample_mmmd_metadynamics(\n    mol: openff.toolkit.Molecule,\n    off_ff: openff.toolkit.ForceField,\n    device: torch.device,\n    settings: settings.MMMDMetadynamicsSamplingSettings,\n    output_paths: dict[OutputType, pathlib.Path],\n) -&gt; datasets.Dataset:\n    \"\"\"Generate a dataset of samples from MD with the given MM force field\n    with metadynamics samplings of the torsions. Each torsion is treated as an\n    independent collective variable and biased independently. This function\n    generates samples using the MM potential, and recalculates energies and\n    forces of snapshots from the ML potential.\n\n    Parameters\n    ----------\n    mol : openff.toolkit.Molecule\n        The molecule to sample.\n    off_ff : openff.toolkit.ForceField\n        The MM force field to use for sampling.\n    device : torch.device\n        The device to use for any MD or ML calculations.\n    settings : settings.MMMDMetadynamicsSamplingSettings\n        The sampling settings to use.\n    output_paths: dict[OutputType, PathLike]\n        A mapping of output types to filesystem paths.\n\n    Returns\n    -------\n    datasets.Dataset\n        The generated dataset of samples with energies and forces.\n    \"\"\"\n    # Make sure we have all the required output paths and no others\n    if set(output_paths.keys()) != settings.output_types:\n        raise ValueError(\n            f\"Output paths must contain exactly the keys {settings.output_types}\"\n        )\n\n    mol = _copy_mol_and_add_conformers(mol, settings.n_conformers)\n    interchange = openff.interchange.Interchange.from_smirnoff(\n        off_ff, openff.toolkit.Topology.from_molecules(mol)\n    )\n\n    torsions = get_rot_torsions_by_rot_bond(mol)\n    if not torsions:\n        raise ValueError(\"No rotatable bonds found in the molecule.\")\n\n    # Configure metadynamics\n    bias_variables = _get_torsion_bias_forces(\n        mol,\n        torsions_to_include=_TORSIONS_TO_INCLUDE_SMARTS,\n        torsions_to_exclude=_TORSIONS_TO_EXCLUDE_SMARTS,\n        bias_width=settings.bias_width,\n    )\n\n    system = interchange.to_openmm_system()\n\n    bias_dir = output_paths[OutputType.METADYNAMICS_BIAS]\n    bias_dir.mkdir()\n\n    metad = Metadynamics(  # type: ignore[no-untyped-call]\n        system=system,\n        variables=bias_variables,\n        temperature=settings.temperature,\n        biasFactor=settings.bias_factor,\n        height=settings.bias_height,\n        frequency=settings.n_steps_per_bias,\n        saveFrequency=settings.n_steps_per_bias_save,\n        biasDir=bias_dir,\n        independentCVs=True,\n    )\n\n    simulation = Simulation(\n        interchange.topology.to_openmm(),\n        system,\n        _get_integrator(settings.temperature, settings.timestep),\n    )\n\n    step_fn = functools.partial(metad.step, simulation)\n\n    # First, generate the MD snapshots using the MM potential\n    mm_dataset = _run_md(\n        mol,\n        simulation,\n        step_fn,\n        settings.equilibration_n_steps_per_conformer,\n        settings.production_n_snapshots_per_conformer,\n        settings.production_n_steps_per_snapshot_per_conformer,\n        str(output_paths.get(OutputType.PDB_TRAJECTORY, None)),\n    )\n\n    # Now, recalculate energies and forces using the ML potential\n    ml_system = _get_ml_omm_system(mol, settings.ml_potential)\n    ml_simulation = Simulation(\n        interchange.topology.to_openmm(),\n        ml_system,\n        _get_integrator(settings.temperature, settings.timestep),\n    )\n    ml_dataset = recalculate_energies_and_forces(mm_dataset, ml_simulation)\n\n    return ml_dataset\n</code></pre>"},{"location":"reference/settings/","title":"settings","text":""},{"location":"reference/settings/#bespokefit_smee.settings","title":"settings","text":"<p>Pydantic models which control/validate the settings.</p> <p>Classes:</p> <ul> <li> <code>MMMDSamplingSettings</code>           \u2013            <p>Settings for molecular dynamics sampling using a molecular mechanics</p> </li> <li> <code>MLMDSamplingSettings</code>           \u2013            <p>Settings for molecular dynamics sampling using a machine learning</p> </li> <li> <code>MMMDMetadynamicsSamplingSettings</code>           \u2013            <p>Settings for molecular dynamics sampling using a molecular mechanics</p> </li> <li> <code>RegularisationSettings</code>           \u2013            <p>Settings for regularisation of the force field parameters. Note that</p> </li> <li> <code>TrainingSettings</code>           \u2013            <p>Settings for the training process.</p> </li> <li> <code>MSMSettings</code>           \u2013            <p>Settings for the modified Seminario method.</p> </li> <li> <code>ParameterisationSettings</code>           \u2013            <p>Settings for the starting parameterisation.</p> </li> <li> <code>WorkflowSettings</code>           \u2013            <p>Overall settings for the full fitting workflow.</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.MMMDSamplingSettings","title":"MMMDSamplingSettings","text":"<p>               Bases: <code>_SamplingSettingsBase</code></p> <p>Settings for molecular dynamics sampling using a molecular mechanics force field. This is initally the force field supplined in the parameterisation settings, but is updated as the bespoke force field is trained.</p> <p>Methods:</p> <ul> <li> <code>to_yaml</code>             \u2013              <p>Save the settings to a YAML file</p> </li> <li> <code>from_yaml</code>             \u2013              <p>Load settings from a YAML file</p> </li> <li> <code>validate_sampling_times</code>             \u2013              <p>Ensure that the sampling times divide exactly by the timestep and (for production) the snapshot interval.</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.MMMDSamplingSettings.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(yaml_path: PathLike) -&gt; None\n</code></pre> <p>Save the settings to a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def to_yaml(self, yaml_path: PathLike) -&gt; None:\n    \"\"\"Save the settings to a YAML file\"\"\"\n    data = self.model_dump(mode=\"json\")\n    with open(yaml_path, \"w\") as file:\n        yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MMMDSamplingSettings.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(yaml_path: PathLike) -&gt; Self\n</code></pre> <p>Load settings from a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: PathLike) -&gt; Self:\n    \"\"\"Load settings from a YAML file\"\"\"\n    with open(yaml_path, \"r\") as file:\n        settings_data = yaml.safe_load(file)\n    return cls(**settings_data)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MMMDSamplingSettings.validate_sampling_times","title":"validate_sampling_times","text":"<pre><code>validate_sampling_times() -&gt; Self\n</code></pre> <p>Ensure that the sampling times divide exactly by the timestep and (for production) the snapshot interval.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_sampling_times(self) -&gt; Self:\n    \"\"\"Ensure that the sampling times divide exactly by the timestep and (for production) the snapshot interval.\"\"\"\n    for time, name in [\n        (\n            self.equilibration_sampling_time_per_conformer,\n            \"equilibration_sampling_time_per_conformer\",\n        ),\n        (\n            self.production_sampling_time_per_conformer,\n            \"production_sampling_time_per_conformer\",\n        ),\n    ]:\n        n_steps = time / self.timestep\n        if not n_steps.is_integer():\n            raise InvalidSettingsError(\n                f\"{name} ({time}) must be divisible by the timestep ({self.timestep}).\"\n            )\n\n    # Additionally check that production sampling time divides by snapshot interval\n    time = self.production_sampling_time_per_conformer / self.snapshot_interval\n    if not n_steps.is_integer():\n        raise InvalidSettingsError(\n            f\"production_sampling_time_per_conformer ({time}) must be divisible by the snapshot_interval ({self.snapshot_interval}).\"\n        )\n\n    return self\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MLMDSamplingSettings","title":"MLMDSamplingSettings","text":"<p>               Bases: <code>_SamplingSettingsBase</code></p> <p>Settings for molecular dynamics sampling using a machine learning potential. This protocol uses the ML reference potential for sampling as well as for energy and force calculations.</p> <p>Methods:</p> <ul> <li> <code>to_yaml</code>             \u2013              <p>Save the settings to a YAML file</p> </li> <li> <code>from_yaml</code>             \u2013              <p>Load settings from a YAML file</p> </li> <li> <code>validate_sampling_times</code>             \u2013              <p>Ensure that the sampling times divide exactly by the timestep and (for production) the snapshot interval.</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.MLMDSamplingSettings.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(yaml_path: PathLike) -&gt; None\n</code></pre> <p>Save the settings to a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def to_yaml(self, yaml_path: PathLike) -&gt; None:\n    \"\"\"Save the settings to a YAML file\"\"\"\n    data = self.model_dump(mode=\"json\")\n    with open(yaml_path, \"w\") as file:\n        yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MLMDSamplingSettings.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(yaml_path: PathLike) -&gt; Self\n</code></pre> <p>Load settings from a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: PathLike) -&gt; Self:\n    \"\"\"Load settings from a YAML file\"\"\"\n    with open(yaml_path, \"r\") as file:\n        settings_data = yaml.safe_load(file)\n    return cls(**settings_data)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MLMDSamplingSettings.validate_sampling_times","title":"validate_sampling_times","text":"<pre><code>validate_sampling_times() -&gt; Self\n</code></pre> <p>Ensure that the sampling times divide exactly by the timestep and (for production) the snapshot interval.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_sampling_times(self) -&gt; Self:\n    \"\"\"Ensure that the sampling times divide exactly by the timestep and (for production) the snapshot interval.\"\"\"\n    for time, name in [\n        (\n            self.equilibration_sampling_time_per_conformer,\n            \"equilibration_sampling_time_per_conformer\",\n        ),\n        (\n            self.production_sampling_time_per_conformer,\n            \"production_sampling_time_per_conformer\",\n        ),\n    ]:\n        n_steps = time / self.timestep\n        if not n_steps.is_integer():\n            raise InvalidSettingsError(\n                f\"{name} ({time}) must be divisible by the timestep ({self.timestep}).\"\n            )\n\n    # Additionally check that production sampling time divides by snapshot interval\n    time = self.production_sampling_time_per_conformer / self.snapshot_interval\n    if not n_steps.is_integer():\n        raise InvalidSettingsError(\n            f\"production_sampling_time_per_conformer ({time}) must be divisible by the snapshot_interval ({self.snapshot_interval}).\"\n        )\n\n    return self\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MMMDMetadynamicsSamplingSettings","title":"MMMDMetadynamicsSamplingSettings","text":"<p>               Bases: <code>_SamplingSettingsBase</code></p> <p>Settings for molecular dynamics sampling using a molecular mechanics force field with metadynamics. This is initally the force field supplined in the parameterisation settings, but is updated as the bespoke force field is trained.</p> <p>Methods:</p> <ul> <li> <code>to_yaml</code>             \u2013              <p>Save the settings to a YAML file</p> </li> <li> <code>from_yaml</code>             \u2013              <p>Load settings from a YAML file</p> </li> <li> <code>validate_sampling_times</code>             \u2013              <p>Ensure that the sampling times divide exactly by the timestep and (for production) the snapshot interval.</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.MMMDMetadynamicsSamplingSettings.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(yaml_path: PathLike) -&gt; None\n</code></pre> <p>Save the settings to a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def to_yaml(self, yaml_path: PathLike) -&gt; None:\n    \"\"\"Save the settings to a YAML file\"\"\"\n    data = self.model_dump(mode=\"json\")\n    with open(yaml_path, \"w\") as file:\n        yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MMMDMetadynamicsSamplingSettings.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(yaml_path: PathLike) -&gt; Self\n</code></pre> <p>Load settings from a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: PathLike) -&gt; Self:\n    \"\"\"Load settings from a YAML file\"\"\"\n    with open(yaml_path, \"r\") as file:\n        settings_data = yaml.safe_load(file)\n    return cls(**settings_data)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MMMDMetadynamicsSamplingSettings.validate_sampling_times","title":"validate_sampling_times","text":"<pre><code>validate_sampling_times() -&gt; Self\n</code></pre> <p>Ensure that the sampling times divide exactly by the timestep and (for production) the snapshot interval.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_sampling_times(self) -&gt; Self:\n    \"\"\"Ensure that the sampling times divide exactly by the timestep and (for production) the snapshot interval.\"\"\"\n    for time, name in [\n        (\n            self.equilibration_sampling_time_per_conformer,\n            \"equilibration_sampling_time_per_conformer\",\n        ),\n        (\n            self.production_sampling_time_per_conformer,\n            \"production_sampling_time_per_conformer\",\n        ),\n    ]:\n        n_steps = time / self.timestep\n        if not n_steps.is_integer():\n            raise InvalidSettingsError(\n                f\"{name} ({time}) must be divisible by the timestep ({self.timestep}).\"\n            )\n\n    # Additionally check that production sampling time divides by snapshot interval\n    time = self.production_sampling_time_per_conformer / self.snapshot_interval\n    if not n_steps.is_integer():\n        raise InvalidSettingsError(\n            f\"production_sampling_time_per_conformer ({time}) must be divisible by the snapshot_interval ({self.snapshot_interval}).\"\n        )\n\n    return self\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.RegularisationSettings","title":"RegularisationSettings","text":"<p>               Bases: <code>_DefaultSettings</code></p> <p>Settings for regularisation of the force field parameters. Note that regularisation is applied after scaling the parameters to ensure similar magnitudes.</p> <p>Methods:</p> <ul> <li> <code>to_yaml</code>             \u2013              <p>Save the settings to a YAML file</p> </li> <li> <code>from_yaml</code>             \u2013              <p>Load settings from a YAML file</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>output_types</code>               (<code>set[OutputType]</code>)           \u2013            <p>Return a set of expected output types for the function which</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.RegularisationSettings.output_types","title":"output_types  <code>property</code>","text":"<pre><code>output_types: set[OutputType]\n</code></pre> <p>Return a set of expected output types for the function which implements this settings object. Subclasses should override this method.</p>"},{"location":"reference/settings/#bespokefit_smee.settings.RegularisationSettings.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(yaml_path: PathLike) -&gt; None\n</code></pre> <p>Save the settings to a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def to_yaml(self, yaml_path: PathLike) -&gt; None:\n    \"\"\"Save the settings to a YAML file\"\"\"\n    data = self.model_dump(mode=\"json\")\n    with open(yaml_path, \"w\") as file:\n        yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.RegularisationSettings.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(yaml_path: PathLike) -&gt; Self\n</code></pre> <p>Load settings from a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: PathLike) -&gt; Self:\n    \"\"\"Load settings from a YAML file\"\"\"\n    with open(yaml_path, \"r\") as file:\n        settings_data = yaml.safe_load(file)\n    return cls(**settings_data)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingSettings","title":"TrainingSettings","text":"<p>               Bases: <code>_DefaultSettings</code></p> <p>Settings for the training process.</p> <p>Methods:</p> <ul> <li> <code>to_yaml</code>             \u2013              <p>Save the settings to a YAML file</p> </li> <li> <code>from_yaml</code>             \u2013              <p>Load settings from a YAML file</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingSettings.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(yaml_path: PathLike) -&gt; None\n</code></pre> <p>Save the settings to a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def to_yaml(self, yaml_path: PathLike) -&gt; None:\n    \"\"\"Save the settings to a YAML file\"\"\"\n    data = self.model_dump(mode=\"json\")\n    with open(yaml_path, \"w\") as file:\n        yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.TrainingSettings.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(yaml_path: PathLike) -&gt; Self\n</code></pre> <p>Load settings from a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: PathLike) -&gt; Self:\n    \"\"\"Load settings from a YAML file\"\"\"\n    with open(yaml_path, \"r\") as file:\n        settings_data = yaml.safe_load(file)\n    return cls(**settings_data)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MSMSettings","title":"MSMSettings","text":"<p>               Bases: <code>_DefaultSettings</code></p> <p>Settings for the modified Seminario method.</p> <p>Methods:</p> <ul> <li> <code>to_yaml</code>             \u2013              <p>Save the settings to a YAML file</p> </li> <li> <code>from_yaml</code>             \u2013              <p>Load settings from a YAML file</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>output_types</code>               (<code>set[OutputType]</code>)           \u2013            <p>Return a set of expected output types for the function which</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.MSMSettings.output_types","title":"output_types  <code>property</code>","text":"<pre><code>output_types: set[OutputType]\n</code></pre> <p>Return a set of expected output types for the function which implements this settings object. Subclasses should override this method.</p>"},{"location":"reference/settings/#bespokefit_smee.settings.MSMSettings.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(yaml_path: PathLike) -&gt; None\n</code></pre> <p>Save the settings to a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def to_yaml(self, yaml_path: PathLike) -&gt; None:\n    \"\"\"Save the settings to a YAML file\"\"\"\n    data = self.model_dump(mode=\"json\")\n    with open(yaml_path, \"w\") as file:\n        yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.MSMSettings.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(yaml_path: PathLike) -&gt; Self\n</code></pre> <p>Load settings from a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: PathLike) -&gt; Self:\n    \"\"\"Load settings from a YAML file\"\"\"\n    with open(yaml_path, \"r\") as file:\n        settings_data = yaml.safe_load(file)\n    return cls(**settings_data)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.ParameterisationSettings","title":"ParameterisationSettings","text":"<p>               Bases: <code>_DefaultSettings</code></p> <p>Settings for the starting parameterisation.</p> <p>Methods:</p> <ul> <li> <code>to_yaml</code>             \u2013              <p>Save the settings to a YAML file</p> </li> <li> <code>from_yaml</code>             \u2013              <p>Load settings from a YAML file</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>output_types</code>               (<code>set[OutputType]</code>)           \u2013            <p>Return a set of expected output types for the function which</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.ParameterisationSettings.output_types","title":"output_types  <code>property</code>","text":"<pre><code>output_types: set[OutputType]\n</code></pre> <p>Return a set of expected output types for the function which implements this settings object. Subclasses should override this method.</p>"},{"location":"reference/settings/#bespokefit_smee.settings.ParameterisationSettings.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(yaml_path: PathLike) -&gt; None\n</code></pre> <p>Save the settings to a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def to_yaml(self, yaml_path: PathLike) -&gt; None:\n    \"\"\"Save the settings to a YAML file\"\"\"\n    data = self.model_dump(mode=\"json\")\n    with open(yaml_path, \"w\") as file:\n        yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.ParameterisationSettings.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(yaml_path: PathLike) -&gt; Self\n</code></pre> <p>Load settings from a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: PathLike) -&gt; Self:\n    \"\"\"Load settings from a YAML file\"\"\"\n    with open(yaml_path, \"r\") as file:\n        settings_data = yaml.safe_load(file)\n    return cls(**settings_data)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.WorkflowSettings","title":"WorkflowSettings","text":"<p>               Bases: <code>_DefaultSettings</code></p> <p>Overall settings for the full fitting workflow.</p> <p>Methods:</p> <ul> <li> <code>validate_version</code>             \u2013              <p>Validate version format and check compatibility.</p> </li> <li> <code>validate_device_type</code>             \u2013              <p>Ensure that the requested device type is available.</p> </li> <li> <code>get_path_manager</code>             \u2013              <p>Get the output paths manager for this workflow settings object.</p> </li> <li> <code>to_yaml</code>             \u2013              <p>Save the settings to a YAML file</p> </li> <li> <code>from_yaml</code>             \u2013              <p>Load settings from a YAML file</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>output_types</code>               (<code>set[OutputType]</code>)           \u2013            <p>Return a set of expected output types for the function which</p> </li> </ul>"},{"location":"reference/settings/#bespokefit_smee.settings.WorkflowSettings.output_types","title":"output_types  <code>property</code>","text":"<pre><code>output_types: set[OutputType]\n</code></pre> <p>Return a set of expected output types for the function which implements this settings object. Subclasses should override this method.</p>"},{"location":"reference/settings/#bespokefit_smee.settings.WorkflowSettings.validate_version","title":"validate_version  <code>classmethod</code>","text":"<pre><code>validate_version(value: str) -&gt; str\n</code></pre> <p>Validate version format and check compatibility.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@field_validator(\"version\")\n@classmethod\ndef validate_version(cls, value: str) -&gt; str:\n    \"\"\"Validate version format and check compatibility.\"\"\"\n    try:\n        parsed = Version(value)\n    except Exception as e:\n        raise ValueError(f\"Invalid version format: {value}\") from e\n\n    actual_version = Version(__version__)\n\n    # Raise an error if the major and minor versions do not match\n    if parsed.major != actual_version.major or parsed.minor != actual_version.minor:\n        raise ValueError(\n            f\"Incompatible settings version: {value}. The current bespokefit_smee version is {__version__}. \"\n            f\"Expected {actual_version.major}.{actual_version.minor}.x, got {parsed.major}.{parsed.minor}.x\"\n            \"Please install the correct version of bespokefit_smee or regenerate the settings file.\",\n        )\n\n    return value\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.WorkflowSettings.validate_device_type","title":"validate_device_type  <code>classmethod</code>","text":"<pre><code>validate_device_type(value: TorchDevice) -&gt; TorchDevice\n</code></pre> <p>Ensure that the requested device type is available.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@field_validator(\"device_type\")\n@classmethod\ndef validate_device_type(cls, value: TorchDevice) -&gt; TorchDevice:\n    \"\"\"Ensure that the requested device type is available.\"\"\"\n    if value == \"cuda\" and not torch.cuda.is_available():\n        raise ValueError(\"CUDA is not available on this system.\")\n\n    if value == \"cpu\":\n        warnings.warn(\n            \"Using CPU for training and sampling. This may be slow. Consider using CUDA if available.\",\n            UserWarning,\n            stacklevel=2,\n        )\n\n    return value\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.WorkflowSettings.get_path_manager","title":"get_path_manager","text":"<pre><code>get_path_manager() -&gt; WorkflowPathManager\n</code></pre> <p>Get the output paths manager for this workflow settings object.</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def get_path_manager(self) -&gt; WorkflowPathManager:\n    \"\"\"Get the output paths manager for this workflow settings object.\"\"\"\n    return WorkflowPathManager(\n        output_dir=self.output_dir,\n        n_iterations=self.n_iterations,\n        training_settings=self.training_settings,\n        training_sampling_settings=self.training_sampling_settings,\n        testing_sampling_settings=self.testing_sampling_settings,\n    )\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.WorkflowSettings.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(yaml_path: PathLike) -&gt; None\n</code></pre> <p>Save the settings to a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>def to_yaml(self, yaml_path: PathLike) -&gt; None:\n    \"\"\"Save the settings to a YAML file\"\"\"\n    data = self.model_dump(mode=\"json\")\n    with open(yaml_path, \"w\") as file:\n        yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/settings/#bespokefit_smee.settings.WorkflowSettings.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(yaml_path: PathLike) -&gt; Self\n</code></pre> <p>Load settings from a YAML file</p> Source code in <code>bespokefit_smee/settings.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: PathLike) -&gt; Self:\n    \"\"\"Load settings from a YAML file\"\"\"\n    with open(yaml_path, \"r\") as file:\n        settings_data = yaml.safe_load(file)\n    return cls(**settings_data)\n</code></pre>"},{"location":"reference/train/","title":"train","text":""},{"location":"reference/train/#bespokefit_smee.train","title":"train","text":"<p>Apply OpenFF parameters to molecule, cluster conformers by RMSD and train</p> <p>Classes:</p> <ul> <li> <code>TrainingFnArgs</code>           \u2013            <p>Arguments for training functions.</p> </li> <li> <code>TrainFn</code>           \u2013            <p>A protocol for training functions.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>train_levenberg_marquardt</code>             \u2013              <p>Iterate the training process using the Levenberg-Marquardt algorithm.</p> </li> <li> <code>train_adam</code>             \u2013              <p>Iterate the training process using the Adam optimizer.</p> </li> </ul>"},{"location":"reference/train/#bespokefit_smee.train.TrainingFnArgs","title":"TrainingFnArgs","text":"<p>               Bases: <code>TypedDict</code></p> <p>Arguments for training functions.</p>"},{"location":"reference/train/#bespokefit_smee.train.TrainFn","title":"TrainFn","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol for training functions.</p>"},{"location":"reference/train/#bespokefit_smee.train.train_levenberg_marquardt","title":"train_levenberg_marquardt","text":"<pre><code>train_levenberg_marquardt(\n    trainable_parameters: Tensor,\n    initial_parameters: Tensor,\n    trainable: Trainable,\n    topology: TensorTopology,\n    dataset: Dataset,\n    dataset_test: Dataset,\n    settings: TrainingSettings,\n    output_paths: dict[OutputType, PathLike],\n    device: device,\n) -&gt; tuple[Tensor, Trainable]\n</code></pre> <p>Iterate the training process using the Levenberg-Marquardt algorithm.</p> <p>Returns:</p> <ul> <li> <code>    tuple[torch.Tensor, descent.train.Trainable]</code>           \u2013            <p>The updated parameters and the trainable object.</p> </li> </ul> Source code in <code>bespokefit_smee/train.py</code> <pre><code>@_register_training_fn(\"lm\")\ndef train_levenberg_marquardt(\n    trainable_parameters: torch.Tensor,\n    initial_parameters: torch.Tensor,\n    trainable: descent.train.Trainable,\n    topology: smee.TensorTopology,\n    dataset: datasets.Dataset,\n    dataset_test: datasets.Dataset,\n    settings: TrainingSettings,\n    output_paths: dict[OutputType, PathLike],\n    device: torch.device,\n) -&gt; tuple[torch.Tensor, descent.train.Trainable]:\n    \"\"\"\n    Iterate the training process using the Levenberg-Marquardt algorithm.\n\n    Parameters\n    ----------\n        trainable_parameters: torch.Tensor\n            The parameters to be optimized.\n        initial_parameters: torch.Tensor\n            The initial parameters before training.\n        trainable: descent.train.Trainable\n            The trainable object containing the parameters.\n        topology: smee.TensorTopology\n            The topology of the system.\n        dataset: datasets.Dataset\n            The dataset to be used for training.\n        dataset_test: datasets.Dataset\n            The dataset to be used for testing.\n        settings: TrainingSettings\n            The settings object containing training parameters.\n        output_dir: PathLike\n            The directory to write output files to.\n        output_paths: dict[OutputType, PathLike]\n            A mapping of output types to filesystem paths. The following keys are\n            expected:\n                - OutputType.TENSORBOARD\n                - OutputType.TRAINING_METRICS\n        device: torch.device\n            The device to perform training on.\n\n    Returns\n    -------\n        tuple[torch.Tensor, descent.train.Trainable]\n            The updated parameters and the trainable object.\n    \"\"\"\n    # Make sure we have all the required output paths and no others\n    if set(output_paths.keys()) != settings.output_types:\n        raise ValueError(\n            f\"Output paths must contain exactly the keys {settings.output_types}\"\n        )\n\n    # Run the training with the LM optimiser\n    lm_config = descent.optim.LevenbergMarquardtConfig(\n        mode=\"adaptive\", n_convergence_criteria=2, max_steps=100\n    )\n\n    closure_fn = get_loss_closure_fn(\n        trainable,\n        initial_parameters,\n        topology,\n        dataset,\n        settings.regularisation_settings,\n    )\n\n    correct_fn = trainable.clamp\n\n    report_fn = functools.partial(\n        report,\n        trainable=trainable,\n        topology=topology,\n        dataset_test=dataset_test,\n        metrics_file=output_paths[OutputType.TRAINING_METRICS],\n        experiment_dir=Path(output_paths[OutputType.TENSORBOARD]),\n    )\n\n    trainable_parameters = descent.optim.levenberg_marquardt(\n        trainable_parameters, lm_config, closure_fn, correct_fn, report_fn\n    )\n    trainable_parameters.requires_grad_(True)\n\n    return trainable_parameters, trainable\n</code></pre>"},{"location":"reference/train/#bespokefit_smee.train.train_adam","title":"train_adam","text":"<pre><code>train_adam(\n    trainable_parameters: Tensor,\n    initial_parameters: Tensor,\n    trainable: Trainable,\n    topology: TensorTopology,\n    dataset: Dataset,\n    dataset_test: Dataset,\n    settings: TrainingSettings,\n    output_paths: dict[OutputType, PathLike],\n    device: device,\n) -&gt; tuple[Tensor, Trainable]\n</code></pre> <p>Iterate the training process using the Adam optimizer.</p> <p>Returns:</p> <ul> <li> <code>    tuple[torch.Tensor, descent.train.Trainable]</code>           \u2013            <p>The updated parameters and the trainable object.</p> </li> </ul> Source code in <code>bespokefit_smee/train.py</code> <pre><code>@_register_training_fn(\"adam\")\ndef train_adam(\n    trainable_parameters: torch.Tensor,\n    initial_parameters: torch.Tensor,\n    trainable: descent.train.Trainable,\n    topology: smee.TensorTopology,\n    dataset: datasets.Dataset,\n    dataset_test: datasets.Dataset,\n    settings: TrainingSettings,\n    output_paths: dict[OutputType, PathLike],\n    device: torch.device,\n) -&gt; tuple[torch.Tensor, descent.train.Trainable]:\n    \"\"\"\n    Iterate the training process using the Adam optimizer.\n\n    Parameters\n    ----------\n        trainable_parameters: torch.Tensor\n            The parameters to be optimized.\n        initial_parameters: torch.Tensor\n            The initial parameters before training.\n        trainable: descent.train.Trainable\n            The trainable object containing the parameters.\n        topology: smee.TensorTopology\n            The topology of the system.\n        dataset: datasets.Dataset\n            The dataset to be used for training.\n        dataset_test: datasets.Dataset\n            The dataset to be used for testing.\n        settings: TrainingSettings\n            The settings object containing training parameters.\n        output_paths: dict[OutputType, PathLike]\n            A mapping of output types to filesystem paths. The following keys are\n            expected:\n                - OutputType.TENSORBOARD\n                - OutputType.TRAINING_METRICS\n        device: torch.device\n            The device to perform training on.\n\n    Returns\n    -------\n        tuple[torch.Tensor, descent.train.Trainable]\n            The updated parameters and the trainable object.\n    \"\"\"\n    # Make sure we have all the required output paths and no others\n    if set(output_paths.keys()) != settings.output_types:\n        raise ValueError(\n            f\"Output paths must contain exactly the keys {settings.output_types}\"\n        )\n\n    # run the ML training\n    with open(output_paths[OutputType.TRAINING_METRICS], \"w\") as metrics_file:\n        with open_writer(Path(output_paths[OutputType.TENSORBOARD])) as writer:\n            optimizer = torch.optim.Adam(\n                [trainable_parameters], lr=settings.learning_rate, amsgrad=True\n            )\n            scheduler = torch.optim.lr_scheduler.ExponentialLR(\n                optimizer, gamma=settings.learning_rate_decay\n            )\n            for v in tensorboardX.writer.hparams(\n                {\"optimizer\": \"Adam\", \"lr\": settings.learning_rate}, {}\n            ):\n                writer.file_writer.add_summary(v)\n            for i in tqdm(\n                range(settings.n_epochs),\n                leave=False,\n                colour=\"blue\",\n                desc=\"Optimising MM parameters\",\n            ):\n                loss_trn = prediction_loss(\n                    dataset,\n                    trainable,\n                    trainable_parameters,\n                    initial_parameters,\n                    topology,\n                    settings.loss_force_weight,\n                    settings.regularisation_settings,\n                    str(device),\n                )\n                if i % 10 == 0:\n                    loss_tst = prediction_loss(\n                        dataset_test,\n                        trainable,\n                        trainable_parameters,\n                        initial_parameters,\n                        topology,\n                        settings.loss_force_weight,\n                        settings.regularisation_settings,\n                        str(device),\n                    )\n                    write_metrics(i, loss_trn, loss_tst, writer, metrics_file)\n                loss_trn.backward(retain_graph=True)  # type: ignore[no-untyped-call]\n                # trainable.freeze_grad()\n                optimizer.step()\n                optimizer.zero_grad(set_to_none=True)\n                trainable.clamp(trainable_parameters)\n                if i % settings.learning_rate_decay_step == 0:\n                    scheduler.step()\n        # some book-keeping and outputting\n        loss_tst = prediction_loss(\n            dataset_test,\n            trainable,\n            trainable_parameters,\n            initial_parameters,\n            topology,\n            settings.loss_force_weight,\n            settings.regularisation_settings,\n            str(device),\n        )\n        write_metrics(settings.n_epochs, loss_trn, loss_tst, writer, metrics_file)\n\n        return trainable_parameters, trainable\n</code></pre>"},{"location":"reference/workflow/","title":"workflow","text":""},{"location":"reference/workflow/#bespokefit_smee.workflow","title":"workflow","text":"<p>Implements the overall workflow for fitting a bespoke force field.</p> <p>Functions:</p> <ul> <li> <code>get_bespoke_force_field</code>             \u2013              <p>Fit a bespoke force field. This involves:</p> </li> </ul>"},{"location":"reference/workflow/#bespokefit_smee.workflow.get_bespoke_force_field","title":"get_bespoke_force_field","text":"<pre><code>get_bespoke_force_field(\n    settings: WorkflowSettings, write_settings: bool = True\n) -&gt; ForceField\n</code></pre> <p>Fit a bespoke force field. This involves:</p> <ul> <li>Parameterising a base force field for the target molecule</li> <li>Generating training data (e.g. from high-temperature MD simulations)</li> <li>Optimising the parameters of the force field to reproduce the training data</li> <li>Validating the fitted force field against test data</li> </ul> <p>Parameters:</p> <ul> <li> <code>settings</code>               (<code>WorkflowSettings</code>)           \u2013            <p>The workflow settings to use for fitting the force field.</p> </li> <li> <code>write_settings</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to write the settings to a YAML file in the output directory, by default True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ForceField</code>           \u2013            <p>The fitted bespoke force field.</p> </li> </ul> Source code in <code>bespokefit_smee/workflow.py</code> <pre><code>@use_bespoke_rdkit_toolkit_decorator\ndef get_bespoke_force_field(\n    settings: WorkflowSettings, write_settings: bool = True\n) -&gt; ForceField:\n    \"\"\"\n    Fit a bespoke force field. This involves:\n\n    - Parameterising a base force field for the target molecule\n    - Generating training data (e.g. from high-temperature MD simulations)\n    - Optimising the parameters of the force field to reproduce the training data\n    - Validating the fitted force field against test data\n\n    Parameters\n    ----------\n    settings : WorkflowSettings\n        The workflow settings to use for fitting the force field.\n\n    write_settings : bool, optional\n        Whether to write the settings to a YAML file in the output directory, by default True.\n\n    Returns\n    -------\n    ForceField\n        The fitted bespoke force field.\n    \"\"\"\n    suppress_unwanted_output()\n\n    path_manager = settings.get_path_manager()\n    stage = OutputStage(StageKind.BASE)\n    path_manager.mk_stage_dir(stage)\n\n    if write_settings:\n        settings_output_path = path_manager.get_output_path(\n            stage, OutputType.WORKFLOW_SETTINGS\n        )\n        logger.info(f\"Writing workflow settings to {settings_output_path}.\")\n        # Copy the settings and change the output directory to be \".\" as we save\n        # to the output directory already\n        output_settings = copy.deepcopy(settings)\n        output_settings.output_dir = pathlib.Path(\".\")\n        output_settings.to_yaml(settings_output_path)\n\n    # Parameterise the base force field\n    # TODO: break this down and make the getting the trainable the responsibility of the\n    # train module. Also process everything at the OFF FF level before converting to the\n    # tensor FF (will be a bit of a pain to update to do this though...)\n    off_mol, initial_off_ff, tensor_top, tensor_ff, trainable = parameterise(\n        settings.parameterisation_settings, device=settings.device_type\n    )\n    trainable_parameters = trainable.to_values().to((settings.device))\n    for param in tensor_top.parameters.values():\n        param.assignment_matrix = param.assignment_matrix.to_dense()\n\n    # Get a copy of the initial trainable parameters for regularisation\n    initial_parameters = trainable_parameters.clone().detach()\n\n    # Generate the test data\n    stage = OutputStage(StageKind.TESTING)\n    path_manager.mk_stage_dir(stage)\n    test_sample_fn: SampleFn = _SAMPLING_FNS_REGISTRY[\n        type(settings.testing_sampling_settings)\n    ]\n    logger.info(\"Generating test data\")\n    dataset_test = test_sample_fn(\n        mol=off_mol,\n        off_ff=initial_off_ff,\n        device=settings.device,\n        settings=settings.testing_sampling_settings,\n        output_paths={\n            output_type: path_manager.get_output_path(stage, output_type)\n            for output_type in settings.testing_sampling_settings.output_types\n        },\n    )\n    dataset_test.save_to_disk(\n        path_manager.get_output_path(stage, OutputType.ENERGIES_AND_FORCES)\n    )\n\n    # Write out statistics on the initial force field\n    stage = OutputStage(StageKind.INITIAL_STATISTICS)\n    path_manager.mk_stage_dir(stage)\n    energy_mean, energy_sd, forces_mean, forces_sd = write_scatter(\n        dataset_test,\n        tensor_ff,\n        tensor_top,\n        str(settings.device),\n        path_manager.get_output_path(stage, OutputType.SCATTER),\n    )\n    logger.info(\n        f\"Initial force field statistics: Energy (Mean/SD): {energy_mean:.3e}/{energy_sd:.3e}, Forces (Mean/SD): {forces_mean:.3e}/{forces_sd:.3e}\"\n    )\n    off_ff = convert_to_smirnoff(\n        trainable.to_force_field(trainable_parameters), base=initial_off_ff\n    )\n    off_ff.to_file(path_manager.get_output_path(stage, OutputType.OFFXML))\n\n    train_sample_fn = _SAMPLING_FNS_REGISTRY[type(settings.training_sampling_settings)]\n\n    train_fn = _TRAINING_FNS_REGISTRY[settings.training_settings.optimiser]\n\n    # Train the force field\n    for iteration in tqdm(\n        range(1, settings.n_iterations + 1),  # Start from 1 (0 is untrained)\n        leave=False,\n        colour=\"magenta\",\n        desc=\"Iterating the Fit\",\n    ):\n        stage = OutputStage(StageKind.TRAINING, iteration)\n        path_manager.mk_stage_dir(stage)\n        dataset_train = None  # Only None for the first iteration\n\n        dataset_train_new = train_sample_fn(\n            mol=off_mol,\n            off_ff=initial_off_ff,\n            device=settings.device,\n            settings=settings.training_sampling_settings,\n            output_paths={\n                output_type: path_manager.get_output_path(stage, output_type)\n                for output_type in settings.training_sampling_settings.output_types\n            },\n        )\n\n        # Update training dataset: concatenate if memory is enabled and not the first iteration\n        should_concatenate = settings.memory and dataset_train is not None\n        dataset_train = (\n            datasets.combine.concatenate_datasets([dataset_train, dataset_train_new])\n            if should_concatenate\n            else dataset_train_new\n        )\n        dataset_train.save_to_disk(\n            path_manager.get_output_path(stage, OutputType.ENERGIES_AND_FORCES)\n        )\n\n        train_output_paths = {\n            output_type: path_manager.get_output_path(stage, output_type)\n            for output_type in settings.training_settings.output_types\n        }\n\n        trainable_parameters, trainable = train_fn(\n            trainable_parameters=trainable_parameters,\n            initial_parameters=initial_parameters,\n            trainable=trainable,\n            topology=tensor_top,\n            dataset=dataset_train,\n            dataset_test=dataset_test,\n            settings=settings.training_settings,\n            output_paths=train_output_paths,\n            device=settings.device,\n        )\n\n        for potential_type in trainable._param_types:\n            tensor_ff.potentials_by_type[potential_type].parameters = copy.copy(\n                trainable.to_force_field(trainable_parameters)\n                .potentials_by_type[potential_type]\n                .parameters\n            )\n\n        off_ff = convert_to_smirnoff(\n            trainable.to_force_field(trainable_parameters), base=initial_off_ff\n        )\n        off_ff.to_file(path_manager.get_output_path(stage, OutputType.OFFXML))\n\n        energy_mean_new, energy_sd_new, forces_mean_new, forces_sd_new = write_scatter(\n            dataset_test,\n            tensor_ff,\n            tensor_top,\n            str(settings.device),\n            path_manager.get_output_path(stage, OutputType.SCATTER),\n        )\n        logger.info(\n            f\"Iteration {iteration} force field statistics: Energy (Mean/SD): {energy_mean:.3e}/{energy_sd:.3e}, Forces (Mean/SD): {forces_mean:.3e}/{forces_sd:.3e}\"\n        )\n        logger.info(\n            f\"    Energy Error (Mean): {energy_mean:10.3e}-&gt;{energy_mean_new:10.3e} : Change = {energy_mean_new - energy_mean:10.3e}\"\n        )\n        logger.info(\n            f\"                 (SD):   {energy_sd:10.3e}-&gt;{energy_sd_new:10.3e} : Change = {energy_sd_new - energy_sd:10.3e}\"\n        )\n        logger.info(\n            f\"    Forces Error (Mean): {forces_mean:10.3e}-&gt;{forces_mean_new:10.3e} : Change = {forces_mean_new - forces_mean:10.3e}\"\n        )\n        logger.info(\n            f\"                 (SD):   {forces_sd:10.3e}-&gt;{forces_sd_new:10.3e} : Change = {forces_sd_new - forces_sd:10.3e}\"\n        )\n        energy_mean, energy_sd = energy_mean_new, energy_sd_new\n        forces_mean, forces_sd = forces_mean_new, forces_sd_new\n\n    # Plot\n    analyse_workflow(settings)\n\n    return off_ff\n</code></pre>"},{"location":"reference/writers/","title":"writers","text":""},{"location":"reference/writers/#bespokefit_smee.writers","title":"writers","text":"<p>WRITERS:</p> <p>Output functions for run-fit</p> <p>Functions:</p> <ul> <li> <code>write_scatter</code>             \u2013              <p>Predict and save energies/forces to HDF5.</p> </li> </ul>"},{"location":"reference/writers/#bespokefit_smee.writers.write_scatter","title":"write_scatter","text":"<pre><code>write_scatter(\n    dataset: Dataset,\n    force_field: TensorForceField,\n    topology_in: TensorTopology,\n    device_type: str,\n    filename: PathLike,\n) -&gt; tuple[float, float, float, float]\n</code></pre> <p>Predict and save energies/forces to HDF5.</p> Source code in <code>bespokefit_smee/writers.py</code> <pre><code>def write_scatter(\n    dataset: datasets.Dataset,\n    force_field: smee.TensorForceField,\n    topology_in: smee.TensorTopology,\n    device_type: str,\n    filename: PathLike,\n) -&gt; tuple[float, float, float, float]:\n    \"\"\"Predict and save energies/forces to HDF5.\"\"\"\n    energy_ref_all, energy_pred_all, forces_ref_all, forces_pred_all = predict(\n        dataset,\n        force_field,\n        {dataset[0][\"smiles\"]: topology_in},\n        device_type=device_type,\n        normalize=False,\n    )\n\n    with torch.no_grad():\n        energy_diffs = energy_pred_all - energy_ref_all\n        force_diffs = forces_pred_all - forces_ref_all\n\n        # Save to HDF5\n        with h5py.File(filename, \"w\") as f:\n            f.create_dataset(\"energy_reference\", data=energy_ref_all.cpu().numpy())\n            f.create_dataset(\"energy_predicted\", data=energy_pred_all.cpu().numpy())\n            f.create_dataset(\"energy_differences\", data=energy_diffs.cpu().numpy())\n\n            f.create_dataset(\"forces_reference\", data=forces_ref_all.cpu().numpy())\n            f.create_dataset(\"forces_predicted\", data=forces_pred_all.cpu().numpy())\n            f.create_dataset(\"forces_differences\", data=force_diffs.cpu().numpy())\n\n            f.attrs[\"n_conformers\"] = len(energy_ref_all)\n            f.attrs[\"n_atoms\"] = forces_ref_all.shape[0] // len(energy_ref_all)\n\n        # Summary statistics\n        energy_mean = torch.mean(energy_diffs).item()\n        energy_std = torch.std(energy_diffs).item()\n        forces_mean = torch.mean(force_diffs).item()\n        forces_std = torch.std(force_diffs).item()\n\n        return energy_mean, energy_std, forces_mean, forces_std\n</code></pre>"},{"location":"reference/models/","title":"Index","text":""},{"location":"reference/models/#bespokefit_smee.models","title":"models","text":"<p>Compiled models</p> <p>Modules:</p> <ul> <li> <code>compile_aimnet2_ens_models</code>           \u2013            <p>Script to compile AIMNet2 ensemble models for use in BespokeFit.</p> </li> </ul>"},{"location":"reference/models/compile_aimnet2_ens_models/","title":"compile_aimnet2_ens_models","text":""},{"location":"reference/models/compile_aimnet2_ens_models/#bespokefit_smee.models.compile_aimnet2_ens_models","title":"compile_aimnet2_ens_models","text":"<p>Script to compile AIMNet2 ensemble models for use in BespokeFit.</p> <p>Classes:</p> <ul> <li> <code>EnsembledModel</code>           \u2013            <p>Create ensemble of AIMNet2 models.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>compile_aimnet2_ens_model</code>             \u2013              <p>Compile an AIMNet2 ensemble model.</p> </li> <li> <code>main</code>             \u2013              <p>Main function to compile and save AIMNet2 ensemble models.</p> </li> </ul>"},{"location":"reference/models/compile_aimnet2_ens_models/#bespokefit_smee.models.compile_aimnet2_ens_models.EnsembledModel","title":"EnsembledModel","text":"<pre><code>EnsembledModel(\n    models: List,\n    x=[\"coord\", \"numbers\", \"charge\"],\n    out=[\"energy\", \"forces\", \"charges\"],\n    detach=True,\n)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Create ensemble of AIMNet2 models.</p> Source code in <code>bespokefit_smee/models/compile_aimnet2_ens_models.py</code> <pre><code>def __init__(\n    self,\n    models: List,\n    x=[\"coord\", \"numbers\", \"charge\"],\n    out=[\"energy\", \"forces\", \"charges\"],\n    detach=True,\n):\n    super().__init__()\n    self.models = nn.ModuleList(models)\n    self.x = x\n    self.out = out\n    self.detach = detach\n</code></pre>"},{"location":"reference/models/compile_aimnet2_ens_models/#bespokefit_smee.models.compile_aimnet2_ens_models.compile_aimnet2_ens_model","title":"compile_aimnet2_ens_model","text":"<pre><code>compile_aimnet2_ens_model(\n    model_name: AvailableModels,\n    n_members: int = 4,\n    device: TorchDevice = \"cpu\",\n) -&gt; ScriptModule\n</code></pre> <p>Compile an AIMNet2 ensemble model.</p> <p>Args:     model_name: Name of the AIMNet2 model to compile.     n_members: Number of ensemble members to include.     device: Torch device to load models onto.</p> <p>Returns:     Compiled AIMNet2 ensemble model.</p> Source code in <code>bespokefit_smee/models/compile_aimnet2_ens_models.py</code> <pre><code>def compile_aimnet2_ens_model(\n    model_name: AvailableModels,\n    n_members: int = 4,\n    device: TorchDevice = \"cpu\",\n) -&gt; torch.jit.ScriptModule:\n    \"\"\"Compile an AIMNet2 ensemble model.\n\n    Args:\n        model_name: Name of the AIMNet2 model to compile.\n        n_members: Number of ensemble members to include.\n        device: Torch device to load models onto.\n\n    Returns:\n        Compiled AIMNet2 ensemble model.\n    \"\"\"\n    if model_name not in get_args(AvailableModels):\n        raise ValueError(\n            f\"Invalid model name: {model_name}. Available models are: {get_args(AvailableModels)}\"\n        )\n\n    models = []\n    for i in range(n_members):\n        model = _download_model(model_name, version=i, device=device)\n        models.append(model)\n\n    ensemble_model = EnsembledModel(models=models, detach=False)\n    scripted_model = torch.jit.script(ensemble_model)  # type: ignore[no-untyped-call]\n\n    return scripted_model\n</code></pre>"},{"location":"reference/models/compile_aimnet2_ens_models/#bespokefit_smee.models.compile_aimnet2_ens_models.main","title":"main","text":"<pre><code>main()\n</code></pre> <p>Main function to compile and save AIMNet2 ensemble models.</p> Source code in <code>bespokefit_smee/models/compile_aimnet2_ens_models.py</code> <pre><code>def main():\n    \"\"\"Main function to compile and save AIMNet2 ensemble models.\"\"\"\n    for model_name in get_args(AvailableModels):\n        logger.info(f\"Compiling ensemble model for {model_name}...\")\n        ens_model = compile_aimnet2_ens_model(model_name, n_members=4, device=\"cpu\")\n        save_path = f\"{model_name}_ens.jpt\"\n        ens_model.save(save_path)\n        logger.info(f\"Saved ensemble model to {save_path}\")\n</code></pre>"},{"location":"reference/utils/","title":"Index","text":""},{"location":"reference/utils/#bespokefit_smee.utils","title":"utils","text":"<p>Utilities for the bespokefit_smee package.</p> <p>Modules:</p> <ul> <li> <code>aimnet2</code>           \u2013            <p>Utilities for working with AIMNet2. Mainly taken from</p> </li> <li> <code>rdkit_bespoke_wrapper</code>           \u2013            <p>Bespoke RDKit toolkit wrapper optimized for SMIRNOFF force field assignment.</p> </li> <li> <code>register</code>           \u2013            <p>Utilities for registering functions.</p> </li> <li> <code>typing</code>           \u2013            <p>Typing utilities for the bespokefit_smee package.</p> </li> </ul>"},{"location":"reference/utils/aimnet2/","title":"aimnet2","text":""},{"location":"reference/utils/aimnet2/#bespokefit_smee.utils.aimnet2","title":"aimnet2","text":"<p>Utilities for working with AIMNet2. Mainly taken from https://github.com/openmm/openmm-ml/pull/64 and https://github.com/SimonBoothroyd/befit/blob/main/befit/utils/aimnet2.py</p> <p>See discussion at https://github.com/isayevlab/AIMNet2/issues/15 re ensemble models.</p> <p>See https://github.com/isayevlab/aimnetcentral/blob/47969eb3e29e34824d82a648dd756669c875ecdb/scripts/compile/compile_off.yaml for available models. May compile the ensemble models in future.</p> <p>Classes:</p> <ul> <li> <code>AIMNet2PotentialImplFactory</code>           \u2013            <p>This is the factory that creates AIMNet2PotentialImpl objects.</p> </li> <li> <code>AIMNet2PotentialImpl</code>           \u2013            <p>This is the MLPotentialImpl implementing the AIMNet2 potential.</p> </li> </ul>"},{"location":"reference/utils/aimnet2/#bespokefit_smee.utils.aimnet2.AIMNet2PotentialImplFactory","title":"AIMNet2PotentialImplFactory","text":"<p>               Bases: <code>MLPotentialImplFactory</code></p> <p>This is the factory that creates AIMNet2PotentialImpl objects.</p>"},{"location":"reference/utils/aimnet2/#bespokefit_smee.utils.aimnet2.AIMNet2PotentialImpl","title":"AIMNet2PotentialImpl","text":"<pre><code>AIMNet2PotentialImpl(name: str)\n</code></pre> <p>               Bases: <code>MLPotentialImpl</code></p> <p>This is the MLPotentialImpl implementing the AIMNet2 potential.</p> Source code in <code>bespokefit_smee/utils/aimnet2.py</code> <pre><code>def __init__(self, name: str):\n    self.name = name\n</code></pre>"},{"location":"reference/utils/rdkit_bespoke_wrapper/","title":"rdkit_bespoke_wrapper","text":""},{"location":"reference/utils/rdkit_bespoke_wrapper/#bespokefit_smee.utils.rdkit_bespoke_wrapper","title":"rdkit_bespoke_wrapper","text":"<p>Bespoke RDKit toolkit wrapper optimized for SMIRNOFF force field assignment.</p> <p>Classes:</p> <ul> <li> <code>RDKitBespokeToolkitWrapper</code>           \u2013            <p>RDKit toolkit wrapper optimized for SMIRNOFF force field parameter assignment.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>use_bespoke_rdkit_toolkit</code>             \u2013              <p>Context manager that temporarily registers the RDKitBespokeToolkitWrapper (</p> </li> <li> <code>use_bespoke_rdkit_toolkit_decorator</code>             \u2013              <p>Decorator that runs the wrapped synchronous function inside the</p> </li> </ul>"},{"location":"reference/utils/rdkit_bespoke_wrapper/#bespokefit_smee.utils.rdkit_bespoke_wrapper.RDKitBespokeToolkitWrapper","title":"RDKitBespokeToolkitWrapper","text":"<pre><code>RDKitBespokeToolkitWrapper()\n</code></pre> <p>               Bases: <code>RDKitToolkitWrapper</code></p> <p>RDKit toolkit wrapper optimized for SMIRNOFF force field parameter assignment.</p> <p>This wrapper uses symmetry perception to dramatically speed up SMARTS matching for highly symmetric molecules by deduplicating chemically equivalent matches.</p> <p>Key differences from RDKitToolkitWrapper: - SMARTS matching uses symmetry perception to avoid exponential match explosion - Partial charge assignment methods are disabled (use specialized toolkits instead)</p> <p>Examples:</p> <p>For a highly symmetric molecule with 24,000 SMARTS matches, this toolkit will return only the ~10-50 unique chemical environments instead.</p> <pre><code>&gt;&gt;&gt; toolkit = RDKitBespokeToolkitWrapper()\n&gt;&gt;&gt; matches = toolkit.find_smarts_matches(molecule, '[C:1]-[C:2]')\n</code></pre> Notes <p>This is specifically designed for force field parameter assignment workflows where you only need to know which unique chemical environments exist, not enumerate all symmetry-equivalent permutations.</p> <p>Methods:</p> <ul> <li> <code>assign_partial_charges</code>             \u2013              <p>Raises an error - use specialized charge assignment toolkits instead.</p> </li> </ul> Source code in <code>bespokefit_smee/utils/rdkit_bespoke_wrapper.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__()\n    logger.info(\n        \"Using RDKitBespokeToolkitWrapper with symmetry-aware SMARTS matching. \"\n        \"This will significantly speed up matching for molecules where each type \"\n        \" matches only one set of symmetry-equivalent atoms.\"\n    )\n</code></pre>"},{"location":"reference/utils/rdkit_bespoke_wrapper/#bespokefit_smee.utils.rdkit_bespoke_wrapper.RDKitBespokeToolkitWrapper.assign_partial_charges","title":"assign_partial_charges","text":"<pre><code>assign_partial_charges(\n    molecule: Molecule,\n    partial_charge_method: str | None = None,\n    use_conformers: bool | None = None,\n    strict_n_conformers: bool = False,\n    normalize_partial_charges: bool = True,\n    _cls: type | None = None,\n) -&gt; None\n</code></pre> <p>Raises an error - use specialized charge assignment toolkits instead.</p> <p>The RDKitBespokeToolkitWrapper is optimized for SMARTS matching in force field parameter assignment, not charge calculation. For partial charges, use: - AmberToolsToolkitWrapper for AM1-BCC charges - OpenEyeToolkitWrapper for high-quality AM1-BCC charges - NAGLToolkitWrapper for graph neural network charges</p> <p>Raises:</p> <ul> <li> <code>ChargeMethodUnavailableError</code>             \u2013            <p>Always raised to redirect users to appropriate charge methods</p> </li> </ul> Source code in <code>bespokefit_smee/utils/rdkit_bespoke_wrapper.py</code> <pre><code>def assign_partial_charges(\n    self,\n    molecule: \"Molecule\",\n    partial_charge_method: str | None = None,\n    use_conformers: bool | None = None,\n    strict_n_conformers: bool = False,\n    normalize_partial_charges: bool = True,\n    _cls: type | None = None,\n) -&gt; None:\n    \"\"\"\n    Raises an error - use specialized charge assignment toolkits instead.\n\n    The RDKitBespokeToolkitWrapper is optimized for SMARTS matching in force field\n    parameter assignment, not charge calculation. For partial charges, use:\n    - AmberToolsToolkitWrapper for AM1-BCC charges\n    - OpenEyeToolkitWrapper for high-quality AM1-BCC charges\n    - NAGLToolkitWrapper for graph neural network charges\n\n    Raises\n    ------\n    ChargeMethodUnavailableError\n        Always raised to redirect users to appropriate charge methods\n    \"\"\"\n    raise ChargeMethodUnavailableError(\n        \"RDKitBespokeToolkitWrapper does not support partial charge assignment. \"\n        \"This toolkit is optimized for fast SMARTS matching in force field parameter \"\n        \"assignment. For partial charges, please use:\\n\"\n        \"  - AmberToolsToolkitWrapper for AM1-BCC charges\\n\"\n        \"  - OpenEyeToolkitWrapper for high-quality AM1-BCC charges\\n\"\n        \"  - NAGLToolkitWrapper for graph neural network charges\"\n    )\n</code></pre>"},{"location":"reference/utils/rdkit_bespoke_wrapper/#bespokefit_smee.utils.rdkit_bespoke_wrapper.use_bespoke_rdkit_toolkit","title":"use_bespoke_rdkit_toolkit","text":"<pre><code>use_bespoke_rdkit_toolkit() -&gt; (\n    Generator[ToolkitRegistry, None, None]\n)\n</code></pre> <p>Context manager that temporarily registers the RDKitBespokeToolkitWrapper ( which ensures fast SMARTS matching for highly symmetric molecules) with the OpenFF toolkit registry and restores the original registry on exit.</p> <p>Yields:</p> <ul> <li> <code>GLOBAL_TOOLKIT_REGISTRY</code>           \u2013            <p>The OpenFF GLOBAL_TOOLKIT_REGISTRY while the context is active.</p> </li> </ul> Source code in <code>bespokefit_smee/utils/rdkit_bespoke_wrapper.py</code> <pre><code>@contextmanager\ndef use_bespoke_rdkit_toolkit() -&gt; Generator[ToolkitRegistry, None, None]:\n    \"\"\"\n    Context manager that temporarily registers the RDKitBespokeToolkitWrapper (\n    which ensures fast SMARTS matching for highly symmetric molecules) with the\n    OpenFF toolkit registry and restores the original registry on exit.\n\n    Yields\n    ------\n    GLOBAL_TOOLKIT_REGISTRY\n        The OpenFF GLOBAL_TOOLKIT_REGISTRY while the context is active.\n    \"\"\"\n    try:\n        from openff.toolkit.utils.toolkits import GLOBAL_TOOLKIT_REGISTRY\n    except Exception as e:\n        raise RuntimeError(\n            \"Cannot use RDKitBespokeToolkitWrapper context manager: \"\n            \"openff toolkit GLOBAL_TOOLKIT_REGISTRY not available.\"\n        ) from e\n\n    with _registry_lock:\n        # Snapshot the current registry list contents (shallow copy).\n        original_toolkits = list(GLOBAL_TOOLKIT_REGISTRY._toolkits)\n\n        # Find any existing bespoke instances.\n        existing_indices = [\n            i\n            for i, t in enumerate(GLOBAL_TOOLKIT_REGISTRY._toolkits)\n            if isinstance(t, RDKitBespokeToolkitWrapper)\n        ]\n\n        if not existing_indices:\n            # No bespoke toolkit present: create and insert/append as requested.\n            bespoke = RDKitBespokeToolkitWrapper()\n            GLOBAL_TOOLKIT_REGISTRY._toolkits.insert(0, bespoke)\n        else:\n            # Bespoke already present. Move the first one to front.\n            idx = existing_indices[0]\n            if idx != 0:\n                item = GLOBAL_TOOLKIT_REGISTRY._toolkits.pop(idx)\n                GLOBAL_TOOLKIT_REGISTRY._toolkits.insert(0, item)\n\n    try:\n        yield GLOBAL_TOOLKIT_REGISTRY\n\n    finally:\n        # Restore the registry contents in-place so any references to the list remain valid.\n        with _registry_lock:\n            GLOBAL_TOOLKIT_REGISTRY._toolkits[:] = original_toolkits\n</code></pre>"},{"location":"reference/utils/rdkit_bespoke_wrapper/#bespokefit_smee.utils.rdkit_bespoke_wrapper.use_bespoke_rdkit_toolkit_decorator","title":"use_bespoke_rdkit_toolkit_decorator","text":"<pre><code>use_bespoke_rdkit_toolkit_decorator(\n    _func: Callable[P, R],\n) -&gt; Callable[P, R]\n</code></pre> <p>Decorator that runs the wrapped synchronous function inside the <code>use_bespoke_rdkit_toolkit()</code> context manager.</p> <p>Usage:   - @use_bespoke_rdkit_toolkit_decorator</p> <p>Note: async functions are not supported and will raise TypeError.</p> Source code in <code>bespokefit_smee/utils/rdkit_bespoke_wrapper.py</code> <pre><code>def use_bespoke_rdkit_toolkit_decorator(_func: Callable[P, R]) -&gt; Callable[P, R]:\n    \"\"\"\n    Decorator that runs the wrapped synchronous function inside the\n    `use_bespoke_rdkit_toolkit()` context manager.\n\n    Usage:\n      - @use_bespoke_rdkit_toolkit_decorator\n\n    Note: async functions are not supported and will raise TypeError.\n    \"\"\"\n\n    def _decorate(func: Callable[P, R]) -&gt; Callable[P, R]:\n        if inspect.iscoroutinefunction(func):\n            raise TypeError(\n                \"use_bespoke_rdkit_toolkit_decorator does not support async functions.\"\n            )\n\n        @wraps(func)\n        def _wrapper(*args: P.args, **kwargs: P.kwargs) -&gt; R:\n            with use_bespoke_rdkit_toolkit():\n                return func(*args, **kwargs)\n\n        return _wrapper\n\n    return _decorate(_func)\n</code></pre>"},{"location":"reference/utils/register/","title":"register","text":""},{"location":"reference/utils/register/#bespokefit_smee.utils.register","title":"register","text":"<p>Utilities for registering functions.</p> <p>Functions:</p> <ul> <li> <code>get_registry_decorator</code>             \u2013              <p>Get a decorator to register functions in a given registry.</p> </li> </ul>"},{"location":"reference/utils/register/#bespokefit_smee.utils.register.get_registry_decorator","title":"get_registry_decorator","text":"<pre><code>get_registry_decorator(\n    registry: dict[Any, Any],\n) -&gt; Callable[[Any], Callable[[FnTypeVar], FnTypeVar]]\n</code></pre> <p>Get a decorator to register functions in a given registry.</p> <p>Parameters:</p> <ul> <li> <code>registry</code>               (<code>dict</code>)           \u2013            <p>The registry to register functions in.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Callable[[Any], Callable[[FnTypeVar], FnTypeVar]]</code>           \u2013            <p>A decorator to register functions in the registry.</p> </li> </ul> Source code in <code>bespokefit_smee/utils/register.py</code> <pre><code>def get_registry_decorator(\n    registry: dict[Any, Any],\n) -&gt; Callable[[Any], Callable[[FnTypeVar], FnTypeVar]]:\n    \"\"\"Get a decorator to register functions in a given registry.\n\n    Parameters\n    ----------\n    registry : dict\n        The registry to register functions in.\n\n    Returns\n    -------\n    Callable[[Any], Callable[[FnTypeVar], FnTypeVar]]\n        A decorator to register functions in the registry.\n    \"\"\"\n\n    def register_fn(\n        key: Any,\n    ) -&gt; Callable[[FnTypeVar], FnTypeVar]:\n        \"\"\"Decorator to register a function in a given registry.\n\n        Parameters\n        ----------\n        key : Any\n            The key to register the function under.\n\n        Returns\n        -------\n        Callable[[FnTypeVar], FnTypeVar]\n            A decorator that registers the function in the registry.\n        \"\"\"\n\n        def decorator(func: FnTypeVar) -&gt; FnTypeVar:\n            if key in registry:\n                raise ValueError(f\"Key {key} is already registered.\")\n            registry[key] = func\n            return func\n\n        return decorator\n\n    return register_fn\n</code></pre>"},{"location":"reference/utils/typing/","title":"typing","text":""},{"location":"reference/utils/typing/#bespokefit_smee.utils.typing","title":"typing","text":"<p>Typing utilities for the bespokefit_smee package.</p> <p>Attributes:</p> <ul> <li> <code>OptimiserName</code>           \u2013            <p>Allowed optimiser names. 'adam' is Adam, 'lm' is Levenberg-Marquardt.</p> </li> </ul>"},{"location":"reference/utils/typing/#bespokefit_smee.utils.typing.OptimiserName","title":"OptimiserName  <code>module-attribute</code>","text":"<pre><code>OptimiserName = Literal['adam', 'lm']\n</code></pre> <p>Allowed optimiser names. 'adam' is Adam, 'lm' is Levenberg-Marquardt.</p>"}]}